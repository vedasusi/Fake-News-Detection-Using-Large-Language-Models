{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b76690b-cac5-4248-8930-4953e2f5914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Directories\n",
    "image_dir = r\"C:\\Users\\golla\\Desktop\\BTECH\\8THSEM\"\n",
    "csv_path = \"final_data.csv\"\n",
    "\n",
    "# Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "213e039e-b572-4d19-98a2-a1471ad27e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModel(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Pre-trained ResNet-50 Model and Modify Last Layer\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False  # Freeze all layers except the last one\n",
    "        self.resnet.fc = nn.Linear(2048, 2)  # Modify last layer for binary classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "resnet_model = ResNetModel().to(device)\n",
    "resnet_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "276b2ce5-909f-4ff1-a49b-34a773d2bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Text Classifier Model\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.xlmr = xlmr_model\n",
    "        for param in self.xlmr.parameters():\n",
    "            param.requires_grad = False  # Freeze pre-trained layers\n",
    "        self.fc = nn.Linear(768, 2)  # Modify last layer\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.xlmr(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.fc(outputs.pooler_output)\n",
    "\n",
    "text_model = TextClassifier().to(device)\n",
    "text_model.train()\n",
    "\n",
    "# Define Loss and Optimizer (Only Fine-Tuning Last Layer)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(resnet_model.resnet.fc.parameters()) + list(text_model.fc.parameters()), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d7e228a-d5f1-44c3-bfc6-2c2ef754a095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNetModel(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick Fine-Tuning for Few Iterations\n",
    "def fine_tune(model, loader):\n",
    "    model.train()\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, masks, labels = batch\n",
    "        inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)\n",
    "        outputs = model(inputs, masks)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Fine-tuning complete.\")\n",
    "\n",
    "fine_tune(text_model, text_loader)  # Fine-tune for text\n",
    "resnet_model.train()  # Ensure ResNet is in training mode for quick fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70c641cd-7e53-4110-b56c-541b056e6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):  டிரம்ப் சாத்தியமான அமைச்சரவை உறுப்பினர்களின் பெயர்களுடன் நிறுத்தவில்லை, அமெரிக்காவை பாதுகாப்பானதாக மாற்ற வடிவமைக்கப்பட்ட கொள்கைகளையும் இரட்டிப்பாக்கினார்.அமெரிக்காவின் தேசிய பாதுகாப்பை அரசியல் சரியான தன்மைக்கு முன் வைக்க டிரம்ப் பரிந்துரைக்கும் போது தாராளவாதிகள் ஏன் இவ்வளவு புண்படுத்தப்படுகிறார்கள் என்று வாக்காளர்கள் கேட்க வேண்டும்? டொனால்ட் டிரம்ப் தனது இரண்டு சர்ச்சைக்குரிய கொள்கை திட்டங்களில் ஒட்டிக்கொண்டிருக்கிறார், இப்போது அவர் குடியரசுக் கட்சியின் ஊக ஜனாதிபதி வேட்பாளராக மாறிவிட்டார்.தீவிரவாதத்தின் ஆபத்துக்கள் காரணமாக ஜனாதிபதியாக தேர்ந்தெடுக்கப்பட்டால், அவர் நாட்டிற்குள் நுழைவதை தற்காலிகமாகப் பட்டி செய்வதற்கான தனது திட்டத்திற்கு அவர் நிற்கிறார் என்று எஸ் லெஸ்டர் ஹோல்ட். அவர் கூறுகையில், நாம் விழிப்புடன் இருக்க வேண்டும்.சட்டவிரோதமாக நாட்டில் வசிக்கும் 11 மில்லியன் மக்கள் அனைவரையும் நாடு கடத்துவதற்கான தனது திட்டத்திலும் டிரம்ப் நிற்கிறார். ஆம், அவர்கள் நாடு கடத்தப்படுவார்கள் என்று அவர் கூறுகிறார்.சிலரைத் திரும்ப அனுமதிக்கும் ஒரு அமைப்பை அவர் வைக்க விரும்புகிறார். டொனால்ட் டிரம்ப் ஒரு துணை ஜனாதிபதி சோதனை குழுவை அமைப்பதை மிக விரைவில் கூறுகிறார், அதில் அவரது முன்னாள் இயங்கும் தோழர்கள் சிலர் சேர்க்கலாம்.தனது சாத்தியமான இயங்கும் தோழர்களை அவர் இன்னும் தீவிரமாக பரிசீலிக்கத் தொடங்கவில்லை என்று கூறினார். பென் கார்சன் மற்றும் கிறிஸ் கிறிஸ்டி ஆகியோரை அவர் குழுவில் வைக்கலாம் என்று அவர் கூறுகிறார். டொனால்ட் டிரம்ப் ஜனாதிபதியாக தேர்ந்தெடுக்கப்பட்டால் சில அமைச்சரவை தேர்வுகளை வெளிப்படுத்துகிறார். ஃபாக்ஸ் நியூஸ் எஸ் உடனான நேர்காணலில் ஒரு நேர்காணல்ஓ ரெய்லி காரணி, முன்னறிவிப்பு GOP வேட்பாளர் கூறுகையில், முன்னாள் நியூயார்க் நகர மேயர் ரூடி கியுலியானி உள்நாட்டுப் பாதுகாப்பு செயலாளர் கோவ் என்று பெயரிடுவதைக் கருத்தில் கொள்வதாகக் கூறுகிறார்.கிறிஸ் கிறிஸ்டி அட்டர்னி ஜெனரல் மற்றும் டாக்டர்.பென் கார்சன் சுகாதார மற்றும் மனித சேவைகளின் செயலாளர். அவர் இறுதி முடிவுகளை எடுக்கவில்லை என்று அவர் கூறுகிறார், ஆனால் நிச்சயமாக அவர்கள் மூன்று புத்திசாலித்தனமான தேர்வுகள்.கார்சன் தனது துணையாக இருப்பதில் ஆர்வம் காட்டவில்லை என்றும் டிரம்ப் கூறினார்.வழியாக: ஆப்\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):  \ttext 180\tkabul (reuters) - afghanistan s telecoms regulator wrote to internet service providers this week ordering them to block the messaging services whatsapp and telegram but it was not immediately clear whether they had complied. use of social media and mobile instant messaging services has exploded in afghanistan over recent years. social media users and civil rights groups reacted with outrage to initial reports of the move and the letter sent by telecoms regulator atra was widely shared on social media.   some media reports, citing unidentified sources, said the move had been ordered by the national directorate for security to thwart the use of the encrypted messaging services by the taliban and other insurgent groups. it was not immediately possible to confirm the reports. the acting minister for telecommunications, shahzad aryobee, posted a message on facebook saying that the telecoms regulator had been ordered to put a gradual block on the services to improve their functioning after complaints had been received. the government is committed to freedom of speech and knows that it is a basic civil right for our people, he wrote. the letter by telecoms regulator atra, dated nov. 1 and signed by an official of the regulator, directed internet companies to block telegram and facebook inc s (fb.o) whatsapp services without delay for a period of 20 days. however, the service worked normally this week and still appeared to be working normally on saturday on both state-owned operator salaam and private service providers. on friday, there were reports of interruptions but it was not clear whether they were caused by a deliberate shutdown or by the unrelated issues with whatsapp services that were experienced in several countries. mobile phone services have been one of the big success stories in afghanistan since the taliban were ousted from power by a u.s.-led campaign in 2001, but there are also frequent complaints from users about quality and coverage. whatsapp and similar services, including facebook messenger and viber, are widely used by afghan politicians and members of the government as well as by the taliban, which has a sophisticated social media operation of its own. the movement s main spokesman, zabihullah mujahid, wrote to reporters this week giving his viber number in case whatsapp is not working .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):  \ttext 188\tవాషింగ్టన్ (రాయిటర్స్) - ఫెడరల్ హెల్త్‌కేర్ ఇన్సూరెన్స్ కవరేజ్ పొందే అక్రమ వలసదారులను అణిచివేసేందుకు ఉద్దేశించిన నిబంధనను తొలగించడానికి రిపబ్లికన్ నాయకులు ఒబామాకేర్ రోల్‌బ్యాక్ బిల్లును సర్దుబాటు చేసిన తరువాత వాషింగ్టన్లో కొంతమంది సంప్రదాయవాదులు మంగళవారం మంగళవారం మంగళవారం ఫ్యూమ్ అయ్యారు.U.S. లో రిపబ్లికన్ నాయకులకు ఈ అభివృద్ధి మరొక సమస్యను కలిగించింది.ప్రతినిధుల సభ మరియు అధ్యక్షుడు డొనాల్డ్ ట్రంప్, విస్తృత బిల్లుకు కాంగ్రెస్ ఆమోదం పొందటానికి ప్రయత్నిస్తున్నారు, ఇది అధికారం చేపట్టినప్పటి నుండి ట్రంప్‌కు మొదటి పెద్ద శాసన పరీక్ష.హెల్త్‌కేర్ టాక్స్ క్రెడిట్స్ యు.ఎస్.పౌరులు మరియు చట్టపరమైన శాశ్వత నివాసితులు, అక్రమ వలసదారులకు కాదు.బిల్లు ప్రకారం పన్ను క్రెడిట్లను నిర్వహించే సెనేట్ ఫైనాన్స్ కమిటీ, హోంల్యాండ్ సెక్యూరిటీ విభాగంలో పరిధిని లేదని సెనేట్ పార్లమెంటు సభ్యుడు నిర్ధారించడంతో, చాలా విధానపరమైన చర్యలో, సెనేట్ పార్లమెంటు సభ్యుడు నిర్ధారించిన తరువాత దీనిని బిల్లు నుండి తొలగించారు.రిపబ్లికన్ ప్రతినిధి లౌ బార్లెట్టా సోమవారం సాయంత్రం ఒక ప్రకటన విడుదల చేశారు, మార్పు చేసిన తరువాత, అస్పష్టమైన నిబంధనను పేర్కొంటూ అతను ఇకపై బిల్లుకు మద్దతు ఇవ్వలేనని చెప్పాడు.\"ఆరోగ్య సంరక్షణ పన్ను క్రెడిట్ల కోసం దరఖాస్తు చేసుకున్న వ్యక్తి ఈ దేశంలో చట్టబద్ధంగా మరియు వాటిని స్వీకరించడానికి అర్హులు కాదా అని ధృవీకరించడానికి ఈ బిల్లుకు తగిన భద్రతలు లేవని నేను ఆందోళన చెందుతున్నాను\" అని పెన్సిల్వేనియా చట్టసభ సభ్యుడు చెప్పారు.ట్రంప్ అడ్మినిస్ట్రేషన్ అమెరికన్ హెల్త్ కేర్ యాక్ట్ అని పిలువబడే బిల్లును ఆమోదించడానికి చేసిన ప్రయత్నాలలో ట్రంప్ పరిపాలన గెలవడానికి ప్రయత్నిస్తున్న ఈ నిబంధన ఒక ముఖ్య సమస్యగా ఉంది, ఒబామాకేర్‌ను రద్దు చేయడానికి మరియు కొంతవరకు భర్తీ చేయడానికి ట్రంప్ యొక్క ప్రణాళిక.రిపబ్లికన్ హౌస్ నాయకత్వం ఈ నెల ప్రారంభంలో దీనిని ఆవిష్కరించినప్పటి నుండి కొంతమంది సంప్రదాయవాదులు ఈ బిల్లును విమర్శించారు, దీనిని \"ఒబామాకేర్ లైట్\" అని పిలిచారు, ఎందుకంటే డెమొక్రాటిక్ మాజీ అధ్యక్షుడు బరాక్ ఒబామా యొక్క 2010 ఆరోగ్య సంరక్షణ చట్టాన్ని రద్దు చేయడంలో ఇది చాలా తక్కువగా ఉందని వారు చెప్పారు.సాంప్రదాయిక మరియు మితమైన విమర్శకులను సంతృప్తిపరిచే ఆశతో రిపబ్లికన్ నాయకులు సోమవారం ఈ బిల్లును పున ra సృష్టి చేశారు.ఈ బిల్లుకు మరింత మద్దతు పొందాలని కోరుతూ ట్రంప్ మంగళవారం కాపిటల్ హిల్‌ను సందర్శించారు.మార్గాలు మరియు మార్గాలపై పన్ను-రచన హౌస్ కమిటీ ప్రతినిధి లారెన్ అరోన్సన్ మాట్లాడుతూ, యు.ఎస్. మాత్రమే పేర్కొనే ఒబామాకేర్ యొక్క అంతర్లీన విధానాలను బిల్లు ఉంచుతుంది.పౌరులు మరియు చట్టపరమైన శాశ్వత నివాసితులు పన్ను క్రెడిట్లకు అర్హులు.ఈ బిల్లు గురువారం ఓటు కోసం పూర్తి సభ ముందు వెళ్తుందని భావించారు.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):  \ttext 10795\tओबामा एकोर्न के लिए एक वकील हुआ करते थे।\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):  \ttext 10810\tचूंकि स्वीडन विविधता और बहुसंस्कृतिवाद के लिए #1 गंतव्य बन गया, इसलिए वे दुनिया की बलात्कार की राजधानी बन गए, दुनिया!बलात्कार ने आसमान छू लिया है क्योंकि शरणार्थी पुनर्वास में काफी वृद्धि हुई है।स्वीडिश पुलिस स्वीडिश महिलाओं को चेतावनी दे रही है कि वे अंधेरे के बाद बाहर न जाएं।यह बहुत खतरनाक है!क्या आप इस पर विश्वास करोगे?सुरम्य स्टर्सुंड में अधिकारियों ने विदेशी पुरुषों के गिरोहों के बाद की चेतावनी जारी की, जब वे सड़क पर महिलाओं का बलात्कार करने और यहां तक ​​कि एक बस स्टॉप पर 10 साल की लड़कियों के एक समूह को पकड़ने का प्रयास करते हैं। चौंकाने वाली घोषणा के आसपास चिंताओं को बढ़ाएगा।स्वीडन पर बड़े पैमाने पर प्रवास के प्रभाव, जो कि अधिक समय में 150,000 मुख्य रूप से मुस्लिम प्रवासियों को एकीकृत करने के लिए संघर्ष कर रहा है। सेंट्रल स्वीडन में स्टर्सुंड के छोटे लेकसाइड शहर में, पिछले दो हफ्तों में सेक्स हमलों के साथ आतंकित किया गया है।।सभी मामलों में पुरुष हमलावर, अक्सर गिरोहों में अभिनय करते हैं, उन्हें विदेशी उपस्थिति के रूप में वर्णित किया गया था। हमले आते हैं क्योंकि स्वीडिश अधिकारियों ने छोटे शहर में एक शरणार्थी रिसेप्शन सेंटर में प्रवासियों की बढ़ती संख्या को भेजना शुरू कर दिया है क्योंकि सभी आवास आगे दक्षिण में हैं।पहले से ही भरा हुआ है। एक असाधारण प्रेस कॉन्फ्रेंस में कल पुलिस प्रमुखों ने महिलाओं को एक आश्चर्यजनक चेतावनी जारी की, उन्हें बताते हुए कि स्टर्सुंड अब इतना असुरक्षित है कि उन्हें अकेले अंधेरे के बाद बाहर नहीं जाना चाहिए।क्षेत्रीय पुलिस प्रमुख स्टीफन जेरैंड ने कहा कि हमले असामान्य थे क्योंकि अपराधियों में से कोई भी नशे में दिखाई नहीं दिया, यह कहते हुए कि अधिकारियों ने शहर में एक चिंताजनक प्रवृत्ति देखी है।तीन लोग।जो कुछ भी है वह यह भी है कि इन अपराधियों में से कोई भी प्रभाव में नहीं रहा है।अब पुलिस बाहर जा रही है और शहर में अकेले यात्रा करने के खिलाफ महिलाओं को चेतावनी दे रही है।हमने एक चिंताजनक प्रवृत्ति देखी है।यह गंभीर है, हम महिलाओं की सुरक्षा के बारे में परवाह करते हैं और इसीलिए हम बाहर जा रहे हैं और इस बारे में बात कर रहे हैं।सबसे हालिया हमला रविवार सुबह के शुरुआती घंटों में हुआ, जब तीन युवकों ने शहर के केंद्र में एक महिला का बलात्कार करने का प्रयास किया।और पढ़ें: एक्सप्रेस\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):  \ttext 10819\tBRUSSELS (रायटर) - संयुक्त राज्य अमेरिका एकतरफा रूप से ईरान और विश्व शक्तियों के बीच 2015 परमाणु समझौते को रद्द नहीं कर सकता है, यूरोपीय संघ की विदेश नीति के प्रमुख फेडेरिका मोगेरिनी ने शुक्रवार को राष्ट्रपति डोनाल्ड ट्रम्प के समझौते को प्रमाणित नहीं करने के फैसले की प्रतिक्रिया में कहा।\"हम एक परमाणु समझौते को खत्म करने के लिए अंतर्राष्ट्रीय समुदाय के रूप में बर्दाश्त नहीं कर सकते, जो काम कर रहा है,\" मोगेरिनी ने कहा, जिन्होंने लैंडमार्क वार्ता के अंतिम चरणों की अध्यक्षता की।\"यह सौदा एक द्विपक्षीय समझौता नहीं है ... अंतर्राष्ट्रीय समुदाय, और इसके साथ यूरोपीय संघ ने स्पष्ट रूप से संकेत दिया है कि सौदा है, और होगा, जगह में जारी रहेगा,\" मोगेरिनी ने संवाददाताओं से कहा।Mogherini ने कहा कि उसने यू.एस. से बात कीशुक्रवार को ट्रम्प के भाषण के तुरंत बाद राज्य के सचिव रेक्स टिलरसन।\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):   C:\\Users\\golla\\Desktop\\fake.jpg\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):   C:\\Users\\golla\\Desktop\\real.jpg\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text or image path (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "# Inference Function\n",
    "def predict(user_input):\n",
    "    if os.path.exists(user_input):  # If input is an image\n",
    "        img = Image.open(user_input).convert(\"RGB\")\n",
    "        img = transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        resnet_model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = resnet_model(img).argmax(1).item()\n",
    "        return \"Fake News\" if pred == 1 else \"Real News\"\n",
    "    else:  # If input is text\n",
    "        encoding = tokenizer(user_input, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
    "        \n",
    "        text_model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = text_model(encoding['input_ids'], encoding['attention_mask']).argmax(1).item()\n",
    "        return \"Fake News\" if pred == 1 else \"Real News\"\n",
    "\n",
    "# Keep Asking for Input\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter text or image path (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    print(\"Prediction:\", predict(user_input))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce24014d-351a-46e7-a64c-1622fe7c69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73809d1f-a283-4e1a-a935-4b3e661ed24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Directories\n",
    "image_dir = r\"C:\\Users\\golla\\Desktop\\BTECH\\8THSEM\"\n",
    "csv_path = \"final_data.csv\"\n",
    "\n",
    "# Image Preprocessing (Fixed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6161fe3-af3c-4613-854a-8a2f576c5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained ResNet-50 Model\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False  # Freeze all layers except the last one\n",
    "        self.resnet.fc = nn.Linear(2048, 2)  # Modify last layer for binary classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "resnet_model = ResNetModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded69a38-2c1b-40f7-b710-fed717531ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained XLM-RoBERTa Model\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "xlmr_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# Define Text Classifier Model\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.xlmr = xlmr_model\n",
    "        for param in self.xlmr.parameters():\n",
    "            param.requires_grad = False  # Freeze pre-trained layers\n",
    "        self.fc = nn.Linear(768, 2)  # Modify last layer\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.xlmr(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.fc(outputs.pooler_output)\n",
    "\n",
    "text_model = TextClassifier().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61846f9f-e348-4703-ad3f-5a287bf05355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Multimodal Model\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, resnet_model, text_model):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        self.resnet = resnet_model\n",
    "        self.text_model = text_model\n",
    "        self.fc = nn.Linear(4, 2)  # Combining both outputs (2 from image + 2 from text)\n",
    "\n",
    "    def forward(self, image=None, input_ids=None, attention_mask=None):\n",
    "        image_output = self.resnet(image) if image is not None else torch.zeros((1, 2)).to(device)\n",
    "        text_output = self.text_model(input_ids, attention_mask) if input_ids is not None else torch.zeros((1, 2)).to(device)\n",
    "\n",
    "        combined_output = torch.cat((image_output, text_output), dim=1)\n",
    "        return self.fc(combined_output)\n",
    "\n",
    "# Initialize multimodal model\n",
    "multimodal_model = MultiModalModel(resnet_model, text_model).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd5cb6d-57ab-41b3-9b7e-8c810505ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Class for Multimodal Data\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, image_folder, csv_path, transform, tokenizer):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.texts = []\n",
    "\n",
    "        # Load image data\n",
    "        for label, folder in enumerate([\"real\", \"fake\"]):\n",
    "            folder_path = os.path.join(image_folder, folder)\n",
    "            for filename in os.listdir(folder_path):\n",
    "                self.image_paths.append(os.path.join(folder_path, filename))\n",
    "                self.labels.append(label)\n",
    "\n",
    "        # Load text data\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.text_labels = df[\"label\"].tolist()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.image_paths), len(self.texts))  # Ensure full batch support\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        if idx < len(self.image_paths):\n",
    "            img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "            img = self.transform(img)\n",
    "            img_label = self.labels[idx]\n",
    "        else:\n",
    "            img = torch.zeros((3, 224, 224))  # Placeholder tensor\n",
    "            img_label = -1  # Ignore in accuracy calculation\n",
    "\n",
    "        # Load text\n",
    "        if idx < len(self.texts):\n",
    "            text = self.texts[idx]\n",
    "            if not isinstance(text, str):  \n",
    "                text = \"\"  # Convert None/NaN to empty string to prevent errors\n",
    "\n",
    "            encoding = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
    "            text_label = self.text_labels[idx]\n",
    "        else:\n",
    "            encoding = {\"input_ids\": torch.zeros((1, 256), dtype=torch.long), \"attention_mask\": torch.zeros((1, 256), dtype=torch.long)}\n",
    "            text_label = -1  # Ignore in accuracy calculation\n",
    "\n",
    "        return img, img_label, encoding[\"input_ids\"].squeeze(0), encoding[\"attention_mask\"].squeeze(0), text_label\n",
    "\n",
    "# Load dataset\n",
    "test_dataset = MultiModalDataset(os.path.join(image_dir, \"test\"), csv_path, transform, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40419c5d-2426-4eb8-881b-1375a079d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Calculation for Multimodal Model\n",
    "def evaluate_multimodal(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, img_labels, input_ids, attention_mask, text_labels in loader:\n",
    "            images, img_labels = images.to(device), img_labels.to(device)\n",
    "            input_ids, attention_mask, text_labels = input_ids.to(device), attention_mask.to(device), text_labels.to(device)\n",
    "\n",
    "            outputs = model(image=images, input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.argmax(1)\n",
    "\n",
    "            # Consider only valid labels (ignore -1 cases)\n",
    "            valid_labels = (img_labels >= 0) | (text_labels >= 0)\n",
    "            true_labels = torch.where(img_labels >= 0, img_labels, text_labels)\n",
    "\n",
    "            correct += (predictions[valid_labels] == true_labels[valid_labels]).sum().item()\n",
    "            total += valid_labels.sum().item()\n",
    "\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# Compute Accuracy\n",
    "multimodal_accuracy = evaluate_multimodal(multimodal_model, test_loader)\n",
    "print(f\"Final Multimodal Model Accuracy: {multimodal_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a7559-c1fc-4c47-bbca-770b2573aba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

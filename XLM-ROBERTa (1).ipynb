{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4109fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\golla\\anaconda3\\lib\\site-packages (4.46.0)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/d7/84/0df6c5981f5fc722381662ff8cfbdf8aad64bec875f75d80b55bfef394ce/datasets-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\golla\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\golla\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.23.2 from https://files.pythonhosted.org/packages/ea/da/6c2bea5327b640920267d3bf2c9fc114cfbd0a5de234d81cda80cc9e33c8/huggingface_hub-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\golla\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "   ---------------------------------------- 0.0/464.1 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/464.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/464.1 kB 330.3 kB/s eta 0:00:02\n",
      "   --- ----------------------------------- 41.0/464.1 kB 330.3 kB/s eta 0:00:02\n",
      "   ------ -------------------------------- 71.7/464.1 kB 438.9 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 225.3/464.1 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  460.8/464.1 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 464.1/464.1 kB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface-hub, datasets\n",
      "Successfully installed datasets-3.2.0 huggingface-hub-0.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd037cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2023.5.0\n",
      "  Obtaining dependency information for fsspec==2023.5.0 from https://files.pythonhosted.org/packages/ec/4e/397b234a369df06ec782666fcdf9791d125ca6de48729814b381af8c6c03/fsspec-2023.5.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2023.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fsspec==2023.5.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e2d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad509c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"final_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee102f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct column names\n",
    "df.columns = [\"text\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e2a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to string and label to integer\n",
    "df[\"text\"] = df[\"text\"].astype(str)  # Convert all text to string\n",
    "df[\"label\"] = df[\"label\"].astype(int)  # Convert labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f32f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "588ec5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer for XLM-RoBERTa\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398a4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization Function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "277fa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Convert Data to Hugging Face Dataset Format (Fixed)\n",
    "train_data = Dataset.from_dict({\"text\": list(map(str, train_texts)), \"label\": list(map(int, train_labels))})\n",
    "val_data = Dataset.from_dict({\"text\": list(map(str, val_texts)), \"label\": list(map(int, val_labels))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13ac050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338fed71739840d0b1e1fa4b4696bfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1581 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9c869a622348bcb0568c70913e6d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/396 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize Dataset\n",
    "train_data = train_data.map(tokenize_function, batched=True)\n",
    "val_data = val_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d839e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "842a0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate>=0.26.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d6f427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golla\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training Arguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9515d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golla\\AppData\\Local\\Temp\\ipykernel_4928\\1682246292.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer Object\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc46dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='594' max='594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [594/594 14:18:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>0.255545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=594, training_loss=0.2914544757367786, metrics={'train_runtime': 51536.6669, 'train_samples_per_second': 0.092, 'train_steps_per_second': 0.012, 'total_flos': 1247935735572480.0, 'train_loss': 0.2914544757367786, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53808a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fake-news-multilingual\\\\tokenizer_config.json',\n",
       " './fake-news-multilingual\\\\special_tokens_map.json',\n",
       " './fake-news-multilingual\\\\sentencepiece.bpe.model',\n",
       " './fake-news-multilingual\\\\added_tokens.json',\n",
       " './fake-news-multilingual\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model\n",
    "model.save_pretrained(\"./fake-news-multilingual\")\n",
    "tokenizer.save_pretrained(\"./fake-news-multilingual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f94ca54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2555449903011322, 'eval_runtime': 230.2998, 'eval_samples_per_second': 1.719, 'eval_steps_per_second': 0.217, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36fffbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate Model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(val_data)\n",
    "\n",
    "# Extract logits and labels\n",
    "logits, labels, _ = predictions\n",
    "\n",
    "# Get predicted classes\n",
    "preds = np.argmax(logits, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74aa9a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 641\tபாராளுமன்றத்தின் வெல்ஷ் உறுப்பினர்களின் கூட்டத்தின் போது, ​​பிரதமர் நைகல் எவன்ஸ் ட்ரம்ப் எதிர்ப்பு உறுப்பினர்களை வெட்கினார், அவர்கள் தங்கள் சொந்த ஜனநாயக பதிப்பை முடிவு செய்துள்ளனர் என்பதையும், 61 மில்லியன் அமெரிக்கர்கள் டொனால்ட் டிரம்பை வாக்குப் பெட்டியில் ஆதரித்தார்கள் என்பதையும் நினைவூட்டுகிறது.அவர் அவர்களிடம் சொல்வதன் மூலம் தொடங்கினார்: டொனால்ட் டிரம்பிற்கு அமெரிக்க மக்கள் வாக்களித்தார்கள் என்பதைப் புரிந்துகொள்வது கடினம் என்று கருதுபவர்களுக்கு, அவர் அமெரிக்காவின் ஜனாதிபதியாக இருப்பதால் அதைப் பெறுங்கள்.பிரெக்ஸிட் பிரிட்டிஷ் வாக்காளர்களால் மறந்துவிட்ட பாராளுமன்ற உறுப்பினர்களிடம் வழங்கப்பட்ட வாக்கெடுப்பு என்று பாராளுமன்ற உறுப்பினர்களுக்கு எவன்ஸ் நினைவுபடுத்தினார்.நாம் நம்மை நாமே கேட்டுக்கொள்ள வேண்டும், இது உண்மையில் என்னை உள்ளடக்கியது, நாம் நம்மை நாமே கேட்டுக்கொள்ள வேண்டும், மக்கள் ஏன் தங்களிடம் உள்ள ஜனநாயக முடிவுகளை எடுத்தார்கள் என்று மக்கள் ஏன் விட்டுவிட்டார்கள்?இவர்கள் மறந்துபோனவர்கள், ஐக்கிய இராச்சியத்தில் மறந்துபோனவர்களைப் போலவே, அமெரிக்காவில் மறந்துபோனவர்களும் இருக்கிறார்கள்.அவர் தனது வாக்குறுதிகளை வழங்கிய ஒரே அரசியல்வாதி என்ற வரலாற்றில் அவர் இறங்கப் போகிறார்.ஆனால் உண்மை என்னவென்றால், டொனால்ட் டிரம்பிற்கு வாக்களித்த 61 மில்லியன் மக்கள் இருந்தனர், நாங்கள் இந்த நாட்டில் எழுந்து நின்று, பின்னர் அவரை இனவெறி என்று கண்டனம் செய்தபோது, ​​அதற்கான எந்த ஆதாரமும் நான் காணவில்லை.அவர் இனவெறி கொண்டவர் என்பதற்கான எந்த ஆதாரத்தையும் நான் காணவில்லை அல்லது அவர்கள் அவரை ஒரு அசாதாரணமான முறையில் தாக்கியார்கள் என்பதற்கான எந்த ஆதாரமும் இல்லை, அவரை ஆதரித்த 61 மில்லியன் மக்களை அமெரிக்க மக்களை நாங்கள் உண்மையில் தாக்குகிறோம்.சுருக்கப்பட்ட பதிப்பு இங்கே: இங்கே முழு பதிப்பு:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 638\tஅங்காரா (ராய்ட்டர்ஸ்) - ரஷ்யாவின் சோச்சிக்கு உத்தியோகபூர்வ விஜயத்தின் போது ரஷ்ய ஜனாதிபதி விளாடிமிர் புடினுடன் திட்டமிட்ட மாஸ்கோ ஆதரவு சிரிய காங்கிரஸை விவாதிப்பதாக துருக்கிய ஜனாதிபதி தயிப் எர்டோகன் திங்களன்று தெரிவித்தார்.ரஷ்யா, குவைத் மற்றும் கத்தார் ஆகியோருக்கு புறப்படுவதற்கு முன்பு செய்தியாளர்களிடம் பேசிய எர்டோகன், ரஷ்யாவுடன் விசா இல்லாத பயணத்திற்கு தடைகளை நீக்குமாறு புடினிடம் கேட்பேன் என்றும் கூறினார்.தேசிய உரையாடலில் ரஷ்ய நிதியுதவி அளித்த சிரிய காங்கிரஸ், நவம்பர் மாதத்தில் திட்டமிடப்பட்டுள்ளது.18, ஒத்திவைக்கப்பட்டுள்ளது, துருக்கியின் ஆட்சேபனைகளுக்குப் பிறகு பிரதான சிரிய குர்திஷ் குழு அழைக்கப்படாது என்று எர்டோகன் செய்தித் தொடர்பாளர் கடந்த வாரம் தெரிவித்தார்.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 664\tమా ఇమామ్ యొక్క చీఫ్ 2007 లో అతన్ని ఎన్నుకోవాలనుకున్నప్పుడు అతను క్రైస్తవుడని యునైటెడ్ స్టేట్స్కు చెప్పాడు.అతని నల్లజాతి ఉదారవాద బోధకుడు బరాక్ ఒక సామాజిక నిర్వాహకుడిగా తన స్థితిని పెంచే మార్గంగా మాత్రమే చర్చిని ఉపయోగించాడు. అమెరికన్లకు వ్యతిరేకంగా చాలా దారుణం. ఒక దశాబ్దానికి పైగా, మరియు కొన్ని పరిస్థితులలో కనుగొనటానికి సహాయపడింది.అధ్యక్షుడు బాల్డిమోర్ శనివారం మరియు వైట్ హౌస్ శనివారం ధృవీకరించారు. ముస్లిం అమెరికన్లు మన దేశాన్ని యూనిఫాం మరియు మా పురుషులు మరియు మహిళా యూనిఫాంలో రక్షిస్తారు. ముస్లిం బ్రదర్‌హుడ్ సభ్యుడు, సంస్థను పద్దెనిమిది సంవత్సరాలుగా మార్చారు.యునైటెడ్ స్టేట్స్లో సౌదీ అరేబియా రాయబార కార్యాలయం నుండి పెద్ద సబ్సిడీకి ధార్ అల్-హిజ్రా మసీదు స్థాపించబడింది, ఇది 5,000 మంది ముస్లింలకు వసతి కల్పించడానికి వీలు కల్పించింది.వాషింగ్టన్, డిసి వెలుపల ఉన్న ధార్ అల్-హిజ్రా, ప్రార్థన చేసిన అనేక మంది ఉన్నత స్థాయి ఇస్లామిక్ ఉగ్రవాదులతో ముడిపడి ఉంది, దీనిలో ప్రధాన హసన్ ఫిడేల్ హుడ్ హత్య జిహాదీ, సెప్టెంబర్ 11 కిడ్నాపర్లు మరియు 1993 ప్రపంచ వాణిజ్య కేంద్రాలు\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 679\tవార్సా (రాయిటర్స్) - రష్యన్ సైనిక నిశ్చయత పెరిగిన సమయంలో వలసలు వంటి సమస్యలపై కొన్ని తూర్పు మరియు పాశ్చాత్య యూరోపియన్ యూనియన్ రాష్ట్రాల మధ్య పెరుగుతున్న విభజన.ఐరోపా తూర్పు మరియు సంపన్న పశ్చిమ దేశాలలో మాజీ కమ్యూనిస్ట్ రాష్ట్రాల మధ్య ఘర్షణలు 2015 వలస సంక్షోభం మరియు కూటమిని విడిచిపెట్టడానికి బ్రిటన్ తీసుకున్న నిర్ణయం నుండి పెరిగాయి, ఎందుకంటే నాయకులు EU తో ప్రజాదరణ పొందిన అసంతృప్తిని తగ్గించడానికి ప్రయత్నిస్తున్నారు.పోలాండ్ మరియు హంగేరిలోని జాతీయవాద రాజకీయ నాయకులు బ్రస్సెల్స్ బ్యూరోక్రసీ ఖర్చుతో సభ్య దేశాలకు మరింత అధికారాన్ని తీసుకురావడానికి సంస్కరణను పిలుపునిచ్చారు మరియు మధ్యప్రాచ్యం నుండి వలస వచ్చినవారిని మార్చే ప్రయత్నాలలో పాల్గొనడానికి నిరాకరించారు.ఇది ఒక ఆందోళన అని నేను నమ్ముతున్నాను, లిథువేనియన్ విదేశాంగ మంత్రి లింకేవిసియస్ వార్సాలో ఒక భద్రతా సమావేశం సందర్భంగా, EU లో పోలిష్ మరియు హంగేరియన్ నిశ్చయత గురించి అడిగినప్పుడు, వార్సాలో జరిగిన భద్రతా సమావేశం గురించి రాయిటర్స్‌తో చెప్పారు.మేము మరింత సమైక్యతను చూడాలనుకుంటున్నాము, అతను చెప్పాడు.ఎవరు సంపాదిస్తున్నారో నాకు తెలుసు.మా సమైక్యతతో సంతోషంగా లేని వారు, లింకెవిసియస్ మాట్లాడుతూ, అతను రష్యాను సూచిస్తున్నాడని చెప్పాడు.తూర్పు మరియు పశ్చిమ దేశాలను విభజించాలనుకునే వారికి సహాయం చేయకూడదని మేము చాలా తీవ్రంగా తీసుకుంటున్నాము.లిథువేనియా, పోలాండ్‌తో పాటు, మాస్కో 2014 లో ఉక్రెయిన్ నుండి క్రిమియన్ ద్వీపకల్పాన్ని స్వాధీనం చేసుకున్నప్పటి నుండి రష్యా గురించి ప్రత్యేకించి ఆందోళన చెందుతోంది. నాటో బాల్టిక్స్, పోలాండ్ మరియు నల్ల సముద్రానికి దళాలను పంపడం ద్వారా ఈ ప్రాంతంలోని మిత్రులకు భరోసా ఇవ్వడానికి ప్రయత్నించింది, నాటో నెట్‌వర్క్‌ను ఏర్పాటు చేసిందిఅవుట్‌పోస్టులు, ఎక్కువ వ్యాయామాలు నిర్వహించడం మరియు వేగవంతమైన ప్రతిస్పందన శక్తిని సిద్ధం చేయడం.కొంతమంది పాశ్చాత్య అధికారులు పెద్ద జాతి రష్యన్ మైనారిటీలను కలిగి ఉన్న బాల్టిక్ రాష్ట్రాల భాగాలను మాస్కో స్వాధీనం చేసుకోవచ్చని ఆందోళన వ్యక్తం చేశారు, రష్యా క్రిమియాపై నియంత్రణ సాధించినట్లే.లింకెవిసియస్ మాట్లాడుతూ, EU లో EU పవర్‌హౌస్‌లతో మంచి సంబంధాలు EU లోని జర్మనీ మరియు ఫ్రాన్స్‌లతో కీలకమైనవి ఎందుకంటే సైనికపరంగా సహాయం చేయగల సామర్థ్యం ఉన్నందున.కన్జర్వేటివ్ లా అండ్ జస్టిస్ (పిఐఎస్) పార్టీ అధికారాన్ని తీసుకున్నప్పుడు, సైనిక సేకరణ, యుద్ధకాల నష్టపరిహారం మరియు ఇయు సింగిల్ మార్కెట్ నియమాలు, 2015 నుండి పోలాండ్, 2015 నుండి పారిస్ మరియు బెర్లిన్‌లతో సంబంధాలు క్షీణించాయి.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 660\tvienna (reuters) - at least 3,000 people formed a chain of light in vienna on wednesday to protest against the formation of a government that includes the far-right freedom party. demonstrators holding flickering candles, torches and bicycle lamps encircled the capital s government district.   our republic s most powerful political offices should be exclusively reserved for trustworthy people who are not in the slightest connected to right-wing extremists, said alexander pollak, spokesman for sos mitmensch, one of several human rights groups which organized the demonstration. it was the biggest protest in austria since coalition talks between the conservative people s party (ovp) and the freedom party (fpo) started two weeks ago. organizers estimated the number of people taking part at 8,000 to 10,000, the police at around 3,000. we are here because they (the fpo) feed hatred and want to divide people, said brigitte griesser, holding a candle.   but the protest was far smaller than unrest 17 years ago, when the fpo last formed a government with the ovp and more than 100,000 took to the streets. (the shift to the right) has become a european trend... it s no longer just an austrian issue and that s why it is not that controversial any longer, said protester juergen pucher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 681\tdonald trump spent months on the campaign trail bashing nato, the cornerstone of global security after world war ii. however, president obama said monday that trump is now committed to nato, the alliance he once referred to as obsolete. trump told president obama that he plans to stick with nato, according to the hill. he expressed a great interest in maintaining our core strategic relationships, obama said. and so, one of the messages i will be able to deliver is his commitment to nato and the transatlantic alliance. i think that s one of the most important functions i can serve at this stage during this trip. is to let them know that there is no weakening of resolve when it comes to america s commitment to maintaining a strong and robust nato relationship and a recognition that those alliances aren t just good for europe, they re good for the united states, he continued. and they re vital for the world. so, why the change of heart? trump had no idea how to lead a country. even trump was surprised over the scope of the new job he was elected to do. he has zero political experience, after all. trump s team reportedly was unaware of the fact that he needed to hire a full white house staff upon taking the oval office.and now, trump is going to learn how to be a leader from president obama.trump aides didn t know entire west wing had to be hired; obama, after meeting trump, plans to spend more time w himhttps://t.co/zltpsqswge pic.twitter.com/x4edzsf8uy michael c. bender (@michaelcbender) november 14, 2016that s right. the man conservatives hate is going to babysit donald trump and hold his little hands to guide him through the process. trump thought this would be an easy job. for years, conservatives said obama wasn t experienced enough and called him the community-organizer-in-chief. for the record, obama had many years worth of experience.just to keep score here: trump is not going to fully repeal obamacare. mexico is not going to pay for the wall. and he s now embracing nato. trump voters have been played for suckers.photo by mark wilson via getty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 10399\tन्यू यॉर्क (रायटर) - न्यू जर्सी के गवर्नर क्रिस क्रिस्टी ने एक बेसबॉल प्रशंसक का सामना किया, जिसने मिल्वौकी में रविवार रात के खेल के दौरान उसे स्थानीय मीडिया द्वारा पोस्ट किए गए एक वीडियो के अनुसार, अलोकप्रिय गवर्नर को ऑनलाइन चुटकुलों के एक और दौर का लक्ष्य बना दिया।घटना के एक वीडियो के अनुसार, दूसरे-अवधि के रिपब्लिकन को नाचोस के एक कटोरे को पकड़कर ब्रैड जोसेफ के रूप में पहचाने गए एक व्यक्ति के बारे में बताया जा सकता है, उसे \"आप एक बड़े शॉट,\" सीढ़ियों की उड़ान भरने से पहले, \"आप एक बड़े शॉट\" बताते हैं।मिल्वौकी के WISN टेलीविजन द्वारा ऑनलाइन पोस्ट किया गया।जोसेफ ने स्टेशन को बताया कि उन्होंने क्रिस्टी का नाम चिल्लाया जब राज्यपाल सीढ़ियों से ऊपर जा रहे थे और मिल्वौकी ब्रूवर्स और शिकागो शावकों के बीच खेल के दौरान उन्हें \"पाखंडी\" कहा।“(वह) मुझ पर चिल्ला रहा था।पहले उन्होंने मुझसे कहा, ‘आपके पास एक और बीयर क्यों नहीं है?\"फिर उसने मुझे एक कठिन आदमी कहना शुरू कर दिया।\"क्रिस्टी के कार्यालय के एक प्रतिनिधि ने सोमवार को टिप्पणी के अनुरोध का तुरंत जवाब नहीं दिया।कई सोशल मीडिया उपयोगकर्ताओं ने क्रिस्टी के कार्यों पर अपना गुस्सा व्यक्त करने के लिए ट्विटर पर लिया।कॉमेडियन निक जैक पप्पस ने रविवार को ट्वीट किया, \"क्रिस क्रिस्टी ने सिर्फ साबित किया कि आपकी पैंट को आपकी छाती तक खींची गई पैंट के साथ कठिन दिखना असंभव है।\"ज़ैच थुरमन ने सोमवार को ट्वीट किया, \"यार कस्टा ने उन नाचों को @chrischristie हाथों से बाहर निकाल दिया और उन्हें कहा कि वे 'बंद' सार्वजनिक समुद्र तट पर वापस जाने के लिए कहें, जहां यह सुरक्षित है।\"क्रिस्टी ने इस महीने की शुरुआत में एक न्यू जर्सी स्टेट बीच पर आराम करने के लिए स्लैम होने के बाद एक सरकारी शटडाउन के बीच सुर्खियां बटोरीं, जिसने समुद्र तट को बाकी सभी के लिए सीमा से दूर कर दिया।एक समुद्र तट की कुर्सी में क्रिस्टी की परिवर्तित तस्वीरें इंटरनेट पर फैली हुई हैं, जिसमें उन्हें व्हाइट हाउस की बैठक, फिल्म और टेलीविजन दृश्यों और अन्य अप्रत्याशित सेटिंग्स का चित्रण किया गया है।क्रिस्टी सबसे नापसंद अमेरिकी में से एक हैगवर्नर, जून में एक क्विनिपियाक यूनिवर्सिटी पोल के साथ यह पाते हुए कि 10 न्यू जर्सी मतदाताओं में से आठ नौकरी से अस्वीकार कर रहे थे, जो यह कहा गया था कि यह किसी भी गवर्नर और सबसे कम नौकरी की मंजूरी की रेटिंग थी जो इसे 20 वर्षों में किसी भी गवर्नर के लिए मिली थी।\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 10420\tयदि अमेरिकी राज्य विभाग 16 मार्च से शुरू होने के लिए 120-दिन के ठहराव की तैयारी कर रहा था, तो यह कैसे है कि यह बड़ी संख्या में शरणार्थी विमानों के लिए तैयार थे?क्या कोई प्रभारी (कैरियर के लोगों के अलावा) जनसंख्या, शरणार्थियों और प्रवास ब्यूरो में है?क्या वे अभी भी सभी शॉट्स कह रहे हैं?या, क्या यह संभव है कि व्हाइट हाउस ने कार्यकारी आदेश के इस हिस्से पर लड़ने के लिए तैयार नहीं किया (यह मानते हुए कि हम टी नोटिस नहीं करेंगे)? 342 नए आगमन के बीच शीर्ष पांच राष्ट्रीयताएं इस प्रकार हैं: सीरिया (55 और 51 उनमें से थे।मुस्लिम) सोमालिया (50 और सभी मुस्लिम हैं) बर्मा (44 और उन 17 की आश्चर्यजनक रूप से उच्च संख्या मुस्लिम हैं) इराक (41 और 32 मुस्लिम हैं)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"./fake-news-multilingual\n",
    "\"  # Change this to your fine-tuned model path if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to predict the label\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    label = \"Fake News\" if predicted_class == 1 else \"Real News\"\n",
    "    return label\n",
    "\n",
    "# Get user input and predict\n",
    "while True:\n",
    "    text = input(\"Enter text to classify (or type 'exit' to quit): \")\n",
    "    if text.lower() == \"exit\":\n",
    "        break\n",
    "    prediction = predict(text)\n",
    "    print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a78c94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104e9ff-d679-4fbf-8bc3-623b361c14b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4109fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\golla\\anaconda3\\lib\\site-packages (4.46.0)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/d7/84/0df6c5981f5fc722381662ff8cfbdf8aad64bec875f75d80b55bfef394ce/datasets-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\golla\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\golla\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.23.2 from https://files.pythonhosted.org/packages/ea/da/6c2bea5327b640920267d3bf2c9fc114cfbd0a5de234d81cda80cc9e33c8/huggingface_hub-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\golla\\anaconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\golla\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\golla\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "   ---------------------------------------- 0.0/464.1 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/464.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/464.1 kB 330.3 kB/s eta 0:00:02\n",
      "   --- ----------------------------------- 41.0/464.1 kB 330.3 kB/s eta 0:00:02\n",
      "   ------ -------------------------------- 71.7/464.1 kB 438.9 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 225.3/464.1 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  460.8/464.1 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 464.1/464.1 kB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface-hub, datasets\n",
      "Successfully installed datasets-3.2.0 huggingface-hub-0.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd037cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2023.5.0\n",
      "  Obtaining dependency information for fsspec==2023.5.0 from https://files.pythonhosted.org/packages/ec/4e/397b234a369df06ec782666fcdf9791d125ca6de48729814b381af8c6c03/fsspec-2023.5.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2023.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fsspec==2023.5.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e2d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad509c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"final_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee102f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct column names\n",
    "df.columns = [\"text\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e2a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to string and label to integer\n",
    "df[\"text\"] = df[\"text\"].astype(str)  # Convert all text to string\n",
    "df[\"label\"] = df[\"label\"].astype(int)  # Convert labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f32f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "588ec5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer for XLM-RoBERTa\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398a4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization Function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "277fa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тЬЕ Convert Data to Hugging Face Dataset Format (Fixed)\n",
    "train_data = Dataset.from_dict({\"text\": list(map(str, train_texts)), \"label\": list(map(int, train_labels))})\n",
    "val_data = Dataset.from_dict({\"text\": list(map(str, val_texts)), \"label\": list(map(int, val_labels))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13ac050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338fed71739840d0b1e1fa4b4696bfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1581 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9c869a622348bcb0568c70913e6d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/396 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize Dataset\n",
    "train_data = train_data.map(tokenize_function, batched=True)\n",
    "val_data = val_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d839e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "842a0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate>=0.26.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d6f427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golla\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ЁЯдЧ Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training Arguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9515d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\golla\\AppData\\Local\\Temp\\ipykernel_4928\\1682246292.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer Object\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc46dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='594' max='594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [594/594 14:18:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>0.255545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=594, training_loss=0.2914544757367786, metrics={'train_runtime': 51536.6669, 'train_samples_per_second': 0.092, 'train_steps_per_second': 0.012, 'total_flos': 1247935735572480.0, 'train_loss': 0.2914544757367786, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53808a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fake-news-multilingual\\\\tokenizer_config.json',\n",
       " './fake-news-multilingual\\\\special_tokens_map.json',\n",
       " './fake-news-multilingual\\\\sentencepiece.bpe.model',\n",
       " './fake-news-multilingual\\\\added_tokens.json',\n",
       " './fake-news-multilingual\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model\n",
    "model.save_pretrained(\"./fake-news-multilingual\")\n",
    "tokenizer.save_pretrained(\"./fake-news-multilingual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f94ca54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2555449903011322, 'eval_runtime': 230.2998, 'eval_samples_per_second': 1.719, 'eval_steps_per_second': 0.217, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36fffbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate Model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(val_data)\n",
    "\n",
    "# Extract logits and labels\n",
    "logits, labels, _ = predictions\n",
    "\n",
    "# Get predicted classes\n",
    "preds = np.argmax(logits, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74aa9a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 641\tрокро╛ро░ро╛ро│рпБрооройрпНро▒родрпНродро┐ройрпН ро╡рпЖро▓рпНро╖рпН роЙро▒рпБрокрпНрокро┐ройро░рпНроХро│ро┐ройрпН роХрпВроЯрпНроЯродрпНродро┐ройрпН рокрпЛродрпБ, тАЛтАЛрокро┐ро░родрооро░рпН роирпИроХро▓рпН роОро╡ройрпНро╕рпН роЯрпНро░роорпНрокрпН роОродро┐ро░рпНрокрпНрокрпБ роЙро▒рпБрокрпНрокро┐ройро░рпНроХро│рпИ ро╡рпЖроЯрпНроХро┐ройро╛ро░рпН, роЕро╡ро░рпНроХро│рпН родроЩрпНроХро│рпН роЪрпКроирпНрод роЬройроиро╛ропроХ рокродро┐рокрпНрокрпИ роорпБроЯро┐ро╡рпБ роЪрпЖропрпНродрпБро│рпНро│ройро░рпН роОройрпНрокродрпИропрпБроорпН, 61 рооро┐ро▓рпНро▓ро┐ропройрпН роЕроорпЖро░ро┐роХрпНроХро░рпНроХро│рпН роЯрпКройро╛ро▓рпНроЯрпН роЯро┐ро░роорпНрокрпИ ро╡ро╛роХрпНроХрпБрокрпН рокрпЖроЯрпНроЯро┐ропро┐ро▓рпН роЖродро░ро┐родрпНродро╛ро░рпНроХро│рпН роОройрпНрокродрпИропрпБроорпН роиро┐ройрпИро╡рпВроЯрпНроЯрпБроХро┐ро▒родрпБ.роЕро╡ро░рпН роЕро╡ро░рпНроХро│ро┐роЯроорпН роЪрпКро▓рпНро╡родройрпН роорпВро▓роорпН родрпКроЯроЩрпНроХро┐ройро╛ро░рпН: роЯрпКройро╛ро▓рпНроЯрпН роЯро┐ро░роорпНрокро┐ро▒рпНроХрпБ роЕроорпЖро░ро┐роХрпНроХ роороХрпНроХро│рпН ро╡ро╛роХрпНроХро│ро┐родрпНродро╛ро░рпНроХро│рпН роОройрпНрокродрпИрокрпН рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро╡родрпБ роХроЯро┐ройроорпН роОройрпНро▒рпБ роХро░рпБродрпБрокро╡ро░рпНроХро│рпБроХрпНроХрпБ, роЕро╡ро░рпН роЕроорпЖро░ро┐роХрпНроХро╛ро╡ро┐ройрпН роЬройро╛родро┐рокродро┐ропро╛роХ роЗро░рпБрокрпНрокродро╛ро▓рпН роЕродрпИрокрпН рокрпЖро▒рпБроЩрпНроХро│рпН.рокро┐ро░рпЖроХрпНро╕ро┐роЯрпН рокро┐ро░ро┐роЯрпНроЯро┐ро╖рпН ро╡ро╛роХрпНроХро╛ро│ро░рпНроХро│ро╛ро▓рпН рооро▒роирпНродрпБро╡ро┐роЯрпНроЯ рокро╛ро░ро╛ро│рпБрооройрпНро▒ роЙро▒рпБрокрпНрокро┐ройро░рпНроХро│ро┐роЯроорпН ро╡ро┤роЩрпНроХрокрпНрокроЯрпНроЯ ро╡ро╛роХрпНроХрпЖроЯрпБрокрпНрокрпБ роОройрпНро▒рпБ рокро╛ро░ро╛ро│рпБрооройрпНро▒ роЙро▒рпБрокрпНрокро┐ройро░рпНроХро│рпБроХрпНроХрпБ роОро╡ройрпНро╕рпН роиро┐ройрпИро╡рпБрокроЯрпБродрпНродро┐ройро╛ро░рпН.роиро╛роорпН роироорпНроорпИ роиро╛роорпЗ роХрпЗроЯрпНроЯрпБроХрпНроХрпКро│рпНро│ ро╡рпЗрогрпНроЯрпБроорпН, роЗродрпБ роЙрогрпНроорпИропро┐ро▓рпН роОройрпНройрпИ роЙро│рпНро│роЯроХрпНроХро┐ропродрпБ, роиро╛роорпН роироорпНроорпИ роиро╛роорпЗ роХрпЗроЯрпНроЯрпБроХрпНроХрпКро│рпНро│ ро╡рпЗрогрпНроЯрпБроорпН, роороХрпНроХро│рпН роПройрпН родроЩрпНроХро│ро┐роЯроорпН роЙро│рпНро│ роЬройроиро╛ропроХ роорпБроЯро┐ро╡рпБроХро│рпИ роОроЯрпБродрпНродро╛ро░рпНроХро│рпН роОройрпНро▒рпБ роороХрпНроХро│рпН роПройрпН ро╡ро┐роЯрпНроЯрпБро╡ро┐роЯрпНроЯро╛ро░рпНроХро│рпН?роЗро╡ро░рпНроХро│рпН рооро▒роирпНродрпБрокрпЛройро╡ро░рпНроХро│рпН, роРроХрпНроХро┐роп роЗро░ро╛роЪрпНроЪро┐ропродрпНродро┐ро▓рпН рооро▒роирпНродрпБрокрпЛройро╡ро░рпНроХро│рпИрокрпН рокрпЛро▓ро╡рпЗ, роЕроорпЖро░ро┐роХрпНроХро╛ро╡ро┐ро▓рпН рооро▒роирпНродрпБрокрпЛройро╡ро░рпНроХро│рпБроорпН роЗро░рпБроХрпНроХро┐ро▒ро╛ро░рпНроХро│рпН.роЕро╡ро░рпН родройродрпБ ро╡ро╛роХрпНроХрпБро▒рпБродро┐роХро│рпИ ро╡ро┤роЩрпНроХро┐роп роТро░рпЗ роЕро░роЪро┐ропро▓рпНро╡ро╛родро┐ роОройрпНро▒ ро╡ро░ро▓ро╛ро▒рпНро▒ро┐ро▓рпН роЕро╡ро░рпН роЗро▒роЩрпНроХрокрпН рокрпЛроХро┐ро▒ро╛ро░рпН.роЖройро╛ро▓рпН роЙрогрпНроорпИ роОройрпНройро╡рпЖройрпНро▒ро╛ро▓рпН, роЯрпКройро╛ро▓рпНроЯрпН роЯро┐ро░роорпНрокро┐ро▒рпНроХрпБ ро╡ро╛роХрпНроХро│ро┐родрпНрод 61 рооро┐ро▓рпНро▓ро┐ропройрпН роороХрпНроХро│рпН роЗро░рпБроирпНродройро░рпН, роиро╛роЩрпНроХро│рпН роЗроирпНрод роиро╛роЯрпНроЯро┐ро▓рпН роОро┤рпБроирпНродрпБ роиро┐ройрпНро▒рпБ, рокро┐ройрпНройро░рпН роЕро╡ро░рпИ роЗройро╡рпЖро▒ро┐ роОройрпНро▒рпБ роХрогрпНроЯройроорпН роЪрпЖропрпНродрокрпЛродрпБ, тАЛтАЛроЕродро▒рпНроХро╛рой роОроирпНрод роЖродро╛ро░роорпБроорпН роиро╛ройрпН роХро╛рогро╡ро┐ро▓рпНро▓рпИ.роЕро╡ро░рпН роЗройро╡рпЖро▒ро┐ роХрпКрогрпНроЯро╡ро░рпН роОройрпНрокродро▒рпНроХро╛рой роОроирпНрод роЖродро╛ро░родрпНродрпИропрпБроорпН роиро╛ройрпН роХро╛рогро╡ро┐ро▓рпНро▓рпИ роЕро▓рпНро▓родрпБ роЕро╡ро░рпНроХро│рпН роЕро╡ро░рпИ роТро░рпБ роЕроЪро╛родро╛ро░рогрооро╛рой роорпБро▒рпИропро┐ро▓рпН родро╛роХрпНроХро┐ропро╛ро░рпНроХро│рпН роОройрпНрокродро▒рпНроХро╛рой роОроирпНрод роЖродро╛ро░роорпБроорпН роЗро▓рпНро▓рпИ, роЕро╡ро░рпИ роЖродро░ро┐родрпНрод 61 рооро┐ро▓рпНро▓ро┐ропройрпН роороХрпНроХро│рпИ роЕроорпЖро░ро┐роХрпНроХ роороХрпНроХро│рпИ роиро╛роЩрпНроХро│рпН роЙрогрпНроорпИропро┐ро▓рпН родро╛роХрпНроХрпБроХро┐ро▒рпЛроорпН.роЪрпБро░рпБроХрпНроХрокрпНрокроЯрпНроЯ рокродро┐рокрпНрокрпБ роЗроЩрпНроХрпЗ: роЗроЩрпНроХрпЗ роорпБро┤рпБ рокродро┐рокрпНрокрпБ:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 638\tроЕроЩрпНроХро╛ро░ро╛ (ро░ро╛ропрпНроЯрпНроЯро░рпНро╕рпН) - ро░ро╖рпНропро╛ро╡ро┐ройрпН роЪрпЛроЪрпНроЪро┐роХрпНроХрпБ роЙродрпНродро┐ропрпЛроХрокрпВро░рпНро╡ ро╡ро┐роЬропродрпНродро┐ройрпН рокрпЛродрпБ ро░ро╖рпНроп роЬройро╛родро┐рокродро┐ ро╡ро┐ро│ро╛роЯро┐рооро┐ро░рпН рокрпБроЯро┐ройрпБроЯройрпН родро┐роЯрпНроЯрооро┐роЯрпНроЯ рооро╛ро╕рпНроХрпЛ роЖродро░ро╡рпБ роЪро┐ро░ро┐роп роХро╛роЩрпНроХро┐ро░ро╕рпИ ро╡ро┐ро╡ро╛родро┐рокрпНрокродро╛роХ родрпБро░рпБроХрпНроХро┐роп роЬройро╛родро┐рокродро┐ родропро┐рокрпН роОро░рпНроЯрпЛроХройрпН родро┐роЩрпНроХро│ройрпНро▒рпБ родрпЖро░ро┐ро╡ро┐родрпНродро╛ро░рпН.ро░ро╖рпНропро╛, роХрпБро╡рпИродрпН рооро▒рпНро▒рпБроорпН роХродрпНродро╛ро░рпН роЖроХро┐ропрпЛро░рпБроХрпНроХрпБ рокрпБро▒рокрпНрокроЯрпБро╡родро▒рпНроХрпБ роорпБройрпНрокрпБ роЪрпЖропрпНродро┐ропро╛ро│ро░рпНроХро│ро┐роЯроорпН рокрпЗроЪро┐роп роОро░рпНроЯрпЛроХройрпН, ро░ро╖рпНропро╛ро╡рпБроЯройрпН ро╡ро┐роЪро╛ роЗро▓рпНро▓ро╛род рокропрогродрпНродро┐ро▒рпНроХрпБ родроЯрпИроХро│рпИ роирпАроХрпНроХрпБрооро╛ро▒рпБ рокрпБроЯро┐ройро┐роЯроорпН роХрпЗроЯрпНрокрпЗройрпН роОройрпНро▒рпБроорпН роХрпВро▒ро┐ройро╛ро░рпН.родрпЗроЪро┐роп роЙро░рпИропро╛роЯро▓ро┐ро▓рпН ро░ро╖рпНроп роиро┐родро┐ропрпБродро╡ро┐ роЕро│ро┐родрпНрод роЪро┐ро░ро┐роп роХро╛роЩрпНроХро┐ро░ро╕рпН, роиро╡роорпНрокро░рпН рооро╛родродрпНродро┐ро▓рпН родро┐роЯрпНроЯрооро┐роЯрокрпНрокроЯрпНроЯрпБро│рпНро│родрпБ.18, роТродрпНродро┐ро╡рпИроХрпНроХрокрпНрокроЯрпНроЯрпБро│рпНро│родрпБ, родрпБро░рпБроХрпНроХро┐ропро┐ройрпН роЖроЯрпНроЪрпЗрокройрпИроХро│рпБроХрпНроХрпБрокрпН рокро┐ро▒роХрпБ рокро┐ро░родро╛рой роЪро┐ро░ро┐роп роХрпБро░рпНродро┐ро╖рпН роХрпБро┤рпБ роЕро┤рпИроХрпНроХрокрпНрокроЯро╛родрпБ роОройрпНро▒рпБ роОро░рпНроЯрпЛроХройрпН роЪрпЖропрпНродро┐родрпН родрпКроЯро░рпНрокро╛ро│ро░рпН роХроЯроирпНрод ро╡ро╛ро░роорпН родрпЖро░ро┐ро╡ро┐родрпНродро╛ро░рпН.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 664\tр░ор░╛ р░Зр░ор░╛р░ор▒Н р░пр▒Кр░Хр▒Нр░Х р░Ър▒Ар░лр▒Н 2007 р░▓р▒Л р░Ер░др░ир▒Нр░ир░┐ р░Ор░ир▒Нр░ир▒Бр░Хр▒Лр░╡р░╛р░▓р░ир▒Бр░Хр▒Бр░ир▒Нр░ир░кр▒Нр░кр▒Бр░бр▒Б р░Ер░др░ир▒Б р░Хр▒Нр░░р▒Ир░╕р▒Нр░др░╡р▒Бр░бр░ир░┐ р░пр▒Бр░ир▒Ир░Яр▒Жр░бр▒Н р░╕р▒Нр░Яр▒Зр░Яр▒Нр░╕р▒Нр░Хр▒Б р░Ър▒Жр░кр▒Нр░кр░╛р░бр▒Б.р░Ер░др░ир░┐ р░ир░▓р▒Нр░▓р░Ьр░╛р░др░┐ р░Йр░жр░╛р░░р░╡р░╛р░ж р░мр▒Лр░зр░Хр▒Бр░бр▒Б р░мр░░р░╛р░Хр▒Н р░Тр░Х р░╕р░╛р░ор░╛р░Ьр░┐р░Х р░ир░┐р░░р▒Нр░╡р░╛р░╣р░Хр▒Бр░бр░┐р░Чр░╛ р░др░и р░╕р▒Нр░ер░┐р░др░┐р░ир░┐ р░кр▒Жр░Вр░Ър▒З р░ор░╛р░░р▒Нр░Чр░Вр░Чр░╛ р░ор░╛р░др▒Нр░░р░ор▒З р░Ър░░р▒Нр░Ър░┐р░ир░┐ р░Йр░кр░пр▒Лр░Чр░┐р░Вр░Ър░╛р░бр▒Б. р░Ер░ор▒Жр░░р░┐р░Хр░ир▒Нр░▓р░Хр▒Б р░╡р▒Нр░пр░др░┐р░░р▒Зр░Хр░Вр░Чр░╛ р░Ър░╛р░▓р░╛ р░жр░╛р░░р▒Бр░гр░В. р░Тр░Х р░жр░╢р░╛р░мр▒Нр░жр░╛р░ир░┐р░Хр░┐ р░кр▒Ир░Чр░╛, р░ор░░р░┐р░пр▒Б р░Хр▒Кр░ир▒Нр░ир░┐ р░кр░░р░┐р░╕р▒Нр░ер░┐р░др▒Бр░▓р░▓р▒Л р░Хр░ир▒Бр░Чр▒Кр░ир░Яр░╛р░ир░┐р░Хр░┐ р░╕р░╣р░╛р░пр░кр░бр░┐р░Вр░жр░┐.р░Ер░зр▒Нр░пр░Хр▒Нр░╖р▒Бр░бр▒Б р░мр░╛р░▓р▒Нр░бр░┐р░ор▒Лр░░р▒Н р░╢р░ир░┐р░╡р░╛р░░р░В р░ор░░р░┐р░пр▒Б р░╡р▒Ир░Яр▒Н р░╣р▒Мр░╕р▒Н р░╢р░ир░┐р░╡р░╛р░░р░В р░зр▒Гр░╡р▒Ар░Хр░░р░┐р░Вр░Ър░╛р░░р▒Б. р░ор▒Бр░╕р▒Нр░▓р░┐р░В р░Ер░ор▒Жр░░р░┐р░Хр░ир▒Нр░▓р▒Б р░ор░и р░жр▒Зр░╢р░╛р░ир▒Нр░ир░┐ р░пр▒Вр░ир░┐р░лр░╛р░В р░ор░░р░┐р░пр▒Б р░ор░╛ р░кр▒Бр░░р▒Бр░╖р▒Бр░▓р▒Б р░ор░░р░┐р░пр▒Б р░ор░╣р░┐р░│р░╛ р░пр▒Вр░ир░┐р░лр░╛р░Вр░▓р▒Л р░░р░Хр▒Нр░╖р░┐р░╕р▒Нр░др░╛р░░р▒Б. р░ор▒Бр░╕р▒Нр░▓р░┐р░В р░мр▒Нр░░р░жр░░р▒НтАМр░╣р▒Бр░бр▒Н р░╕р░нр▒Нр░пр▒Бр░бр▒Б, р░╕р░Вр░╕р▒Нр░ер░ир▒Б р░кр░жр▒Нр░жр▒Жр░ир░┐р░ор░┐р░жр░┐ р░╕р░Вр░╡р░др▒Нр░╕р░░р░╛р░▓р▒Бр░Чр░╛ р░ор░╛р░░р▒Нр░Ър░╛р░░р▒Б.р░пр▒Бр░ир▒Ир░Яр▒Жр░бр▒Н р░╕р▒Нр░Яр▒Зр░Яр▒Нр░╕р▒Нр░▓р▒Л р░╕р▒Мр░жр▒А р░Ер░░р▒Зр░мр░┐р░пр░╛ р░░р░╛р░пр░мр░╛р░░ р░Хр░╛р░░р▒Нр░пр░╛р░▓р░пр░В р░ир▒Бр░Вр░бр░┐ р░кр▒Жр░жр▒Нр░ж р░╕р░мр▒Нр░╕р░┐р░бр▒Ар░Хр░┐ р░зр░╛р░░р▒Н р░Ер░▓р▒Н-р░╣р░┐р░Ьр▒Нр░░р░╛ р░ор░╕р▒Ар░жр▒Б р░╕р▒Нр░ер░╛р░кр░┐р░Вр░Ър░мр░бр░┐р░Вр░жр░┐, р░Зр░жр░┐ 5,000 р░ор░Вр░жр░┐ р░ор▒Бр░╕р▒Нр░▓р░┐р░Вр░▓р░Хр▒Б р░╡р░╕р░др░┐ р░Хр░▓р▒Нр░кр░┐р░Вр░Ър░бр░╛р░ир░┐р░Хр░┐ р░╡р▒Ар░▓р▒Б р░Хр░▓р▒Нр░кр░┐р░Вр░Ър░┐р░Вр░жр░┐.р░╡р░╛р░╖р░┐р░Вр░Чр▒Нр░Яр░ир▒Н, р░бр░┐р░╕р░┐ р░╡р▒Жр░▓р▒Бр░кр░▓ р░Йр░ир▒Нр░и р░зр░╛р░░р▒Н р░Ер░▓р▒Н-р░╣р░┐р░Ьр▒Нр░░р░╛, р░кр▒Нр░░р░╛р░░р▒Нр░ер░и р░Ър▒Зр░╕р░┐р░и р░Ер░ир▒Зр░Х р░ор░Вр░жр░┐ р░Йр░ир▒Нр░ир░д р░╕р▒Нр░ер░╛р░пр░┐ р░Зр░╕р▒Нр░▓р░╛р░ор░┐р░Хр▒Н р░Йр░Чр▒Нр░░р░╡р░╛р░жр▒Бр░▓р░др▒Л р░ор▒Бр░бр░┐р░кр░бр░┐ р░Йр░Вр░жр░┐, р░жр▒Ар░ир░┐р░▓р▒Л р░кр▒Нр░░р░зр░╛р░и р░╣р░╕р░ир▒Н р░лр░┐р░бр▒Зр░▓р▒Н р░╣р▒Бр░бр▒Н р░╣р░др▒Нр░п р░Ьр░┐р░╣р░╛р░жр▒А, р░╕р▒Жр░кр▒Нр░Яр▒Жр░Вр░мр░░р▒Н 11 р░Хр░┐р░бр▒Нр░ир░╛р░кр░░р▒Нр░▓р▒Б р░ор░░р░┐р░пр▒Б 1993 р░кр▒Нр░░р░кр░Вр░Ъ р░╡р░╛р░гр░┐р░Ьр▒Нр░п р░Хр▒Зр░Вр░жр▒Нр░░р░╛р░▓р▒Б\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 679\tр░╡р░╛р░░р▒Нр░╕р░╛ (р░░р░╛р░пр░┐р░Яр░░р▒Нр░╕р▒Н) - р░░р░╖р▒Нр░пр░ир▒Н р░╕р▒Ир░ир░┐р░Х р░ир░┐р░╢р▒Нр░Ър░пр░д р░кр▒Жр░░р░┐р░Чр░┐р░и р░╕р░ор░пр░Вр░▓р▒Л р░╡р░▓р░╕р░▓р▒Б р░╡р░Вр░Яр░┐ р░╕р░ор░╕р▒Нр░пр░▓р░кр▒И р░Хр▒Кр░ир▒Нр░ир░┐ р░др▒Вр░░р▒Нр░кр▒Б р░ор░░р░┐р░пр▒Б р░кр░╛р░╢р▒Нр░Ър░╛р░др▒Нр░п р░пр▒Вр░░р▒Лр░кр░┐р░пр░ир▒Н р░пр▒Вр░ир░┐р░пр░ир▒Н р░░р░╛р░╖р▒Нр░Яр▒Нр░░р░╛р░▓ р░ор░зр▒Нр░п р░кр▒Жр░░р▒Бр░Чр▒Бр░др▒Бр░ир▒Нр░и р░╡р░┐р░нр░Ьр░и.р░Рр░░р▒Лр░кр░╛ р░др▒Вр░░р▒Нр░кр▒Б р░ор░░р░┐р░пр▒Б р░╕р░Вр░кр░ир▒Нр░и р░кр░╢р▒Нр░Ър░┐р░о р░жр▒Зр░╢р░╛р░▓р░▓р▒Л р░ор░╛р░Ьр▒А р░Хр░ор▒Нр░пр▒Вр░ир░┐р░╕р▒Нр░Яр▒Н р░░р░╛р░╖р▒Нр░Яр▒Нр░░р░╛р░▓ р░ор░зр▒Нр░п р░Шр░░р▒Нр░╖р░гр░▓р▒Б 2015 р░╡р░▓р░╕ р░╕р░Вр░Хр▒Нр░╖р▒Лр░нр░В р░ор░░р░┐р░пр▒Б р░Хр▒Вр░Яр░ор░┐р░ир░┐ р░╡р░┐р░бр░┐р░Ър░┐р░кр▒Жр░Яр▒Нр░Яр░бр░╛р░ир░┐р░Хр░┐ р░мр▒Нр░░р░┐р░Яр░ир▒Н р░др▒Ар░╕р▒Бр░Хр▒Бр░ир▒Нр░и р░ир░┐р░░р▒Нр░гр░пр░В р░ир▒Бр░Вр░бр░┐ р░кр▒Жр░░р░┐р░Чр░╛р░пр░┐, р░Ор░Вр░жр▒Бр░Хр░Вр░Яр▒З р░ир░╛р░пр░Хр▒Бр░▓р▒Б EU р░др▒Л р░кр▒Нр░░р░Ьр░╛р░жр░░р░г р░кр▒Кр░Вр░жр░┐р░и р░Ер░╕р░Вр░др▒Гр░кр▒Нр░др░┐р░ир░┐ р░др░Чр▒Нр░Чр░┐р░Вр░Ър░бр░╛р░ир░┐р░Хр░┐ р░кр▒Нр░░р░пр░др▒Нр░ир░┐р░╕р▒Нр░др▒Бр░ир▒Нр░ир░╛р░░р▒Б.р░кр▒Лр░▓р░╛р░Вр░бр▒Н р░ор░░р░┐р░пр▒Б р░╣р░Вр░Чр▒Зр░░р░┐р░▓р▒Лр░ир░┐ р░Ьр░╛р░др▒Ар░пр░╡р░╛р░ж р░░р░╛р░Ьр░Хр▒Ар░п р░ир░╛р░пр░Хр▒Бр░▓р▒Б р░мр▒Нр░░р░╕р▒Нр░╕р▒Жр░▓р▒Нр░╕р▒Н р░мр▒Нр░пр▒Вр░░р▒Лр░Хр▒Нр░░р░╕р▒А р░Цр░░р▒Нр░Ър▒Бр░др▒Л р░╕р░нр▒Нр░п р░жр▒Зр░╢р░╛р░▓р░Хр▒Б р░ор░░р░┐р░Вр░д р░Ер░зр░┐р░Хр░╛р░░р░╛р░ир▒Нр░ир░┐ р░др▒Ар░╕р▒Бр░Хр▒Бр░░р░╛р░╡р░бр░╛р░ир░┐р░Хр░┐ р░╕р░Вр░╕р▒Нр░Хр░░р░гр░ир▒Б р░кр░┐р░▓р▒Бр░кр▒Бр░ир░┐р░Ър▒Нр░Ър░╛р░░р▒Б р░ор░░р░┐р░пр▒Б р░ор░зр▒Нр░пр░кр▒Нр░░р░╛р░Ър▒Нр░пр░В р░ир▒Бр░Вр░бр░┐ р░╡р░▓р░╕ р░╡р░Ър▒Нр░Ър░┐р░ир░╡р░╛р░░р░┐р░ир░┐ р░ор░╛р░░р▒Нр░Ър▒З р░кр▒Нр░░р░пр░др▒Нр░ир░╛р░▓р░▓р▒Л р░кр░╛р░▓р▒Нр░Чр▒Кр░ир░бр░╛р░ир░┐р░Хр░┐ р░ир░┐р░░р░╛р░Хр░░р░┐р░Вр░Ър░╛р░░р▒Б.р░Зр░жр░┐ р░Тр░Х р░Жр░Вр░жр▒Лр░│р░и р░Ер░ир░┐ р░ир▒Зр░ир▒Б р░ир░ор▒Нр░ор▒Бр░др▒Бр░ир▒Нр░ир░╛р░ир▒Б, р░▓р░┐р░ер▒Бр░╡р▒Зр░ир░┐р░пр░ир▒Н р░╡р░┐р░жр▒Зр░╢р░╛р░Вр░Ч р░ор░Вр░др▒Нр░░р░┐ р░▓р░┐р░Вр░Хр▒Зр░╡р░┐р░╕р░┐р░пр░╕р▒Н р░╡р░╛р░░р▒Нр░╕р░╛р░▓р▒Л р░Тр░Х р░нр░жр▒Нр░░р░др░╛ р░╕р░ор░╛р░╡р▒Зр░╢р░В р░╕р░Вр░жр░░р▒Нр░нр░Вр░Чр░╛, EU р░▓р▒Л р░кр▒Лр░▓р░┐р░╖р▒Н р░ор░░р░┐р░пр▒Б р░╣р░Вр░Чр▒Зр░░р░┐р░пр░ир▒Н р░ир░┐р░╢р▒Нр░Ър░пр░д р░Чр▒Бр░░р░┐р░Вр░Ър░┐ р░Ер░бр░┐р░Чр░┐р░ир░кр▒Нр░кр▒Бр░бр▒Б, р░╡р░╛р░░р▒Нр░╕р░╛р░▓р▒Л р░Ьр░░р░┐р░Чр░┐р░и р░нр░жр▒Нр░░р░др░╛ р░╕р░ор░╛р░╡р▒Зр░╢р░В р░Чр▒Бр░░р░┐р░Вр░Ър░┐ р░░р░╛р░пр░┐р░Яр░░р▒Нр░╕р▒НтАМр░др▒Л р░Ър▒Жр░кр▒Нр░кр░╛р░░р▒Б.р░ор▒Зр░ор▒Б р░ор░░р░┐р░Вр░д р░╕р░ор▒Ир░Хр▒Нр░пр░др░ир▒Б р░Ър▒Вр░бр░╛р░▓р░ир▒Бр░Хр▒Бр░Вр░Яр▒Бр░ир▒Нр░ир░╛р░ор▒Б, р░Ер░др░ир▒Б р░Ър▒Жр░кр▒Нр░кр░╛р░бр▒Б.р░Ор░╡р░░р▒Б р░╕р░Вр░кр░╛р░жр░┐р░╕р▒Нр░др▒Бр░ир▒Нр░ир░╛р░░р▒Л р░ир░╛р░Хр▒Б р░др▒Жр░▓р▒Бр░╕р▒Б.р░ор░╛ р░╕р░ор▒Ир░Хр▒Нр░пр░др░др▒Л р░╕р░Вр░др▒Лр░╖р░Вр░Чр░╛ р░▓р▒Зр░ир░┐ р░╡р░╛р░░р▒Б, р░▓р░┐р░Вр░Хр▒Жр░╡р░┐р░╕р░┐р░пр░╕р▒Н р░ор░╛р░Яр▒Нр░▓р░╛р░бр▒Бр░др▒В, р░Ер░др░ир▒Б р░░р░╖р▒Нр░пр░╛р░ир▒Б р░╕р▒Вр░Ър░┐р░╕р▒Нр░др▒Бр░ир▒Нр░ир░╛р░бр░ир░┐ р░Ър▒Жр░кр▒Нр░кр░╛р░бр▒Б.р░др▒Вр░░р▒Нр░кр▒Б р░ор░░р░┐р░пр▒Б р░кр░╢р▒Нр░Ър░┐р░о р░жр▒Зр░╢р░╛р░▓р░ир▒Б р░╡р░┐р░нр░Ьр░┐р░Вр░Ър░╛р░▓р░ир▒Бр░Хр▒Бр░ир▒З р░╡р░╛р░░р░┐р░Хр░┐ р░╕р░╣р░╛р░пр░В р░Ър▒Зр░пр░Хр▒Вр░бр░жр░ир░┐ р░ор▒Зр░ор▒Б р░Ър░╛р░▓р░╛ р░др▒Ар░╡р▒Нр░░р░Вр░Чр░╛ р░др▒Ар░╕р▒Бр░Хр▒Бр░Вр░Яр▒Бр░ир▒Нр░ир░╛р░ор▒Б.р░▓р░┐р░ер▒Бр░╡р▒Зр░ир░┐р░пр░╛, р░кр▒Лр░▓р░╛р░Вр░бр▒НтАМр░др▒Л р░кр░╛р░Яр▒Б, р░ор░╛р░╕р▒Нр░Хр▒Л 2014 р░▓р▒Л р░Йр░Хр▒Нр░░р▒Жр░пр░┐р░ир▒Н р░ир▒Бр░Вр░бр░┐ р░Хр▒Нр░░р░┐р░ор░┐р░пр░ир▒Н р░жр▒Нр░╡р▒Ар░кр░Хр░▓р▒Нр░кр░╛р░ир▒Нр░ир░┐ р░╕р▒Нр░╡р░╛р░зр▒Ар░ир░В р░Ър▒Зр░╕р▒Бр░Хр▒Бр░ир▒Нр░ир░кр▒Нр░кр░Яр░┐ р░ир▒Бр░Вр░бр░┐ р░░р░╖р▒Нр░пр░╛ р░Чр▒Бр░░р░┐р░Вр░Ър░┐ р░кр▒Нр░░р░др▒Нр░пр▒Зр░Хр░┐р░Вр░Ър░┐ р░Жр░Вр░жр▒Лр░│р░и р░Ър▒Жр░Вр░жр▒Бр░др▒Лр░Вр░жр░┐. р░ир░╛р░Яр▒Л р░мр░╛р░▓р▒Нр░Яр░┐р░Хр▒Нр░╕р▒Н, р░кр▒Лр░▓р░╛р░Вр░бр▒Н р░ор░░р░┐р░пр▒Б р░ир░▓р▒Нр░▓ р░╕р░ор▒Бр░жр▒Нр░░р░╛р░ир░┐р░Хр░┐ р░жр░│р░╛р░▓р░ир▒Б р░кр░Вр░кр░бр░В р░жр▒Нр░╡р░╛р░░р░╛ р░И р░кр▒Нр░░р░╛р░Вр░др░Вр░▓р▒Лр░ир░┐ р░ор░┐р░др▒Нр░░р▒Бр░▓р░Хр▒Б р░нр░░р▒Лр░╕р░╛ р░Зр░╡р▒Нр░╡р░бр░╛р░ир░┐р░Хр░┐ р░кр▒Нр░░р░пр░др▒Нр░ир░┐р░Вр░Ър░┐р░Вр░жр░┐, р░ир░╛р░Яр▒Л р░ир▒Жр░Яр▒НтАМр░╡р░░р▒Нр░Хр▒НтАМр░ир▒Б р░Пр░░р▒Нр░кр░╛р░Яр▒Б р░Ър▒Зр░╕р░┐р░Вр░жр░┐р░Ер░╡р▒Бр░Яр▒НтАМр░кр▒Лр░╕р▒Нр░Яр▒Бр░▓р▒Б, р░Ор░Хр▒Нр░Хр▒Бр░╡ р░╡р▒Нр░пр░╛р░пр░╛р░ор░╛р░▓р▒Б р░ир░┐р░░р▒Нр░╡р░╣р░┐р░Вр░Ър░бр░В р░ор░░р░┐р░пр▒Б р░╡р▒Зр░Чр░╡р░Вр░др░ор▒Ир░и р░кр▒Нр░░р░др░┐р░╕р▒Нр░кр░Вр░жр░и р░╢р░Хр▒Нр░др░┐р░ир░┐ р░╕р░┐р░жр▒Нр░зр░В р░Ър▒Зр░пр░бр░В.р░Хр▒Кр░Вр░др░ор░Вр░жр░┐ р░кр░╛р░╢р▒Нр░Ър░╛р░др▒Нр░п р░Ер░зр░┐р░Хр░╛р░░р▒Бр░▓р▒Б р░кр▒Жр░жр▒Нр░ж р░Ьр░╛р░др░┐ р░░р░╖р▒Нр░пр░ир▒Н р░ор▒Ир░ир░╛р░░р░┐р░Яр▒Ар░▓р░ир▒Б р░Хр░▓р░┐р░Чр░┐ р░Йр░ир▒Нр░и р░мр░╛р░▓р▒Нр░Яр░┐р░Хр▒Н р░░р░╛р░╖р▒Нр░Яр▒Нр░░р░╛р░▓ р░нр░╛р░Чр░╛р░▓р░ир▒Б р░ор░╛р░╕р▒Нр░Хр▒Л р░╕р▒Нр░╡р░╛р░зр▒Ар░ир░В р░Ър▒Зр░╕р▒Бр░Хр▒Лр░╡р░Ър▒Нр░Ър░ир░┐ р░Жр░Вр░жр▒Лр░│р░и р░╡р▒Нр░пр░Хр▒Нр░др░В р░Ър▒Зр░╢р░╛р░░р▒Б, р░░р░╖р▒Нр░пр░╛ р░Хр▒Нр░░р░┐р░ор░┐р░пр░╛р░кр▒И р░ир░┐р░пр░Вр░др▒Нр░░р░г р░╕р░╛р░зр░┐р░Вр░Ър░┐р░ир░Яр▒Нр░▓р▒З.р░▓р░┐р░Вр░Хр▒Жр░╡р░┐р░╕р░┐р░пр░╕р▒Н р░ор░╛р░Яр▒Нр░▓р░╛р░бр▒Бр░др▒В, EU р░▓р▒Л EU р░кр░╡р░░р▒НтАМр░╣р▒Мр░╕р▒НтАМр░▓р░др▒Л р░ор░Вр░Ър░┐ р░╕р░Вр░мр░Вр░зр░╛р░▓р▒Б EU р░▓р▒Лр░ир░┐ р░Ьр░░р▒Нр░ор░ир▒А р░ор░░р░┐р░пр▒Б р░лр▒Нр░░р░╛р░ир▒Нр░╕р▒НтАМр░▓р░др▒Л р░Хр▒Ар░▓р░Хр░ор▒Ир░ир░╡р░┐ р░Ор░Вр░жр▒Бр░Хр░Вр░Яр▒З р░╕р▒Ир░ир░┐р░Хр░кр░░р░Вр░Чр░╛ р░╕р░╣р░╛р░пр░В р░Ър▒Зр░пр░Чр░▓ р░╕р░╛р░ор░░р▒Нр░ер▒Нр░пр░В р░Йр░ир▒Нр░ир░Вр░жр▒Бр░и.р░Хр░ир▒Нр░Ьр░░р▒Нр░╡р▒Зр░Яр░┐р░╡р▒Н р░▓р░╛ р░Ер░Вр░бр▒Н р░Ьр░╕р▒Нр░Яр░┐р░╕р▒Н (р░кр░┐р░Рр░Ор░╕р▒Н) р░кр░╛р░░р▒Нр░Яр▒А р░Ер░зр░┐р░Хр░╛р░░р░╛р░ир▒Нр░ир░┐ р░др▒Ар░╕р▒Бр░Хр▒Бр░ир▒Нр░ир░кр▒Нр░кр▒Бр░бр▒Б, р░╕р▒Ир░ир░┐р░Х р░╕р▒Зр░Хр░░р░г, р░пр▒Бр░жр▒Нр░зр░Хр░╛р░▓ р░ир░╖р▒Нр░Яр░кр░░р░┐р░╣р░╛р░░р░В р░ор░░р░┐р░пр▒Б р░Зр░пр▒Б р░╕р░┐р░Вр░Чр░┐р░▓р▒Н р░ор░╛р░░р▒Нр░Хр▒Жр░Яр▒Н р░ир░┐р░пр░ор░╛р░▓р▒Б, 2015 р░ир▒Бр░Вр░бр░┐ р░кр▒Лр░▓р░╛р░Вр░бр▒Н, 2015 р░ир▒Бр░Вр░бр░┐ р░кр░╛р░░р░┐р░╕р▒Н р░ор░░р░┐р░пр▒Б р░мр▒Жр░░р▒Нр░▓р░┐р░ир▒НтАМр░▓р░др▒Л р░╕р░Вр░мр░Вр░зр░╛р░▓р▒Б р░Хр▒Нр░╖р▒Ар░гр░┐р░Вр░Ър░╛р░пр░┐.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 660\tvienna (reuters) - at least 3,000 people formed a chain of light in vienna on wednesday to protest against the formation of a government that includes the far-right freedom party. demonstrators holding flickering candles, torches and bicycle lamps encircled the capital s government district.   our republic s most powerful political offices should be exclusively reserved for trustworthy people who are not in the slightest connected to right-wing extremists, said alexander pollak, spokesman for sos mitmensch, one of several human rights groups which organized the demonstration. it was the biggest protest in austria since coalition talks between the conservative people s party (ovp) and the freedom party (fpo) started two weeks ago. organizers estimated the number of people taking part at 8,000 to 10,000, the police at around 3,000. we are here because they (the fpo) feed hatred and want to divide people, said brigitte griesser, holding a candle.   but the protest was far smaller than unrest 17 years ago, when the fpo last formed a government with the ovp and more than 100,000 took to the streets. (the shift to the right) has become a european trend... it s no longer just an austrian issue and that s why it is not that controversial any longer, said protester juergen pucher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 681\tdonald trump spent months on the campaign trail bashing nato, the cornerstone of global security after world war ii. however, president obama said monday that trump is now committed to nato, the alliance he once referred to as obsolete. trump told president obama that he plans to stick with nato, according to the hill. he expressed a great interest in maintaining our core strategic relationships, obama said. and so, one of the messages i will be able to deliver is his commitment to nato and the transatlantic alliance. i think that s one of the most important functions i can serve at this stage during this trip. is to let them know that there is no weakening of resolve when it comes to america s commitment to maintaining a strong and robust nato relationship and a recognition that those alliances aren t just good for europe, they re good for the united states, he continued. and they re vital for the world. so, why the change of heart? trump had no idea how to lead a country. even trump was surprised over the scope of the new job he was elected to do. he has zero political experience, after all. trump s team reportedly was unaware of the fact that he needed to hire a full white house staff upon taking the oval office.and now, trump is going to learn how to be a leader from president obama.trump aides didn t know entire west wing had to be hired; obama, after meeting trump, plans to spend more time w himhttps://t.co/zltpsqswge pic.twitter.com/x4edzsf8uy michael c. bender (@michaelcbender) november 14, 2016that s right. the man conservatives hate is going to babysit donald trump and hold his little hands to guide him through the process. trump thought this would be an easy job. for years, conservatives said obama wasn t experienced enough and called him the community-organizer-in-chief. for the record, obama had many years worth of experience.just to keep score here: trump is not going to fully repeal obamacare. mexico is not going to pay for the wall. and he s now embracing nato. trump voters have been played for suckers.photo by mark wilson via getty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 10399\tрдиреНрдпреВ рдпреЙрд░реНрдХ (рд░рд╛рдпрдЯрд░) - рдиреНрдпреВ рдЬрд░реНрд╕реА рдХреЗ рдЧрд╡рд░реНрдирд░ рдХреНрд░рд┐рд╕ рдХреНрд░рд┐рд╕реНрдЯреА рдиреЗ рдПрдХ рдмреЗрд╕рдмреЙрд▓ рдкреНрд░рд╢рдВрд╕рдХ рдХрд╛ рд╕рд╛рдордирд╛ рдХрд┐рдпрд╛, рдЬрд┐рд╕рдиреЗ рдорд┐рд▓реНрд╡реМрдХреА рдореЗрдВ рд░рд╡рд┐рд╡рд╛рд░ рд░рд╛рдд рдХреЗ рдЦреЗрд▓ рдХреЗ рджреМрд░рд╛рди рдЙрд╕реЗ рд╕реНрдерд╛рдиреАрдп рдореАрдбрд┐рдпрд╛ рджреНрд╡рд╛рд░рд╛ рдкреЛрд╕реНрдЯ рдХрд┐рдП рдЧрдП рдПрдХ рд╡реАрдбрд┐рдпреЛ рдХреЗ рдЕрдиреБрд╕рд╛рд░, рдЕрд▓реЛрдХрдкреНрд░рд┐рдп рдЧрд╡рд░реНрдирд░ рдХреЛ рдСрдирд▓рд╛рдЗрди рдЪреБрдЯрдХреБрд▓реЛрдВ рдХреЗ рдПрдХ рдФрд░ рджреМрд░ рдХрд╛ рд▓рдХреНрд╖реНрдп рдмрдирд╛ рджрд┐рдпрд╛редрдШрдЯрдирд╛ рдХреЗ рдПрдХ рд╡реАрдбрд┐рдпреЛ рдХреЗ рдЕрдиреБрд╕рд╛рд░, рджреВрд╕рд░реЗ-рдЕрд╡рдзрд┐ рдХреЗ рд░рд┐рдкрдмреНрд▓рд┐рдХрди рдХреЛ рдирд╛рдЪреЛрд╕ рдХреЗ рдПрдХ рдХрдЯреЛрд░реЗ рдХреЛ рдкрдХрдбрд╝рдХрд░ рдмреНрд░реИрдб рдЬреЛрд╕реЗрдл рдХреЗ рд░реВрдк рдореЗрдВ рдкрд╣рдЪрд╛рдиреЗ рдЧрдП рдПрдХ рд╡реНрдпрдХреНрддрд┐ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдмрддрд╛рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ, рдЙрд╕реЗ \"рдЖрдк рдПрдХ рдмрдбрд╝реЗ рд╢реЙрдЯ,\" рд╕реАрдврд╝рд┐рдпреЛрдВ рдХреА рдЙрдбрд╝рд╛рди рднрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ, \"рдЖрдк рдПрдХ рдмрдбрд╝реЗ рд╢реЙрдЯ\" рдмрддрд╛рддреЗ рд╣реИрдВредрдорд┐рд▓реНрд╡реМрдХреА рдХреЗ WISN рдЯреЗрд▓реАрд╡рд┐рдЬрди рджреНрд╡рд╛рд░рд╛ рдСрдирд▓рд╛рдЗрди рдкреЛрд╕реНрдЯ рдХрд┐рдпрд╛ рдЧрдпрд╛редрдЬреЛрд╕реЗрдл рдиреЗ рд╕реНрдЯреЗрд╢рди рдХреЛ рдмрддрд╛рдпрд╛ рдХрд┐ рдЙрдиреНрд╣реЛрдВрдиреЗ рдХреНрд░рд┐рд╕реНрдЯреА рдХрд╛ рдирд╛рдо рдЪрд┐рд▓реНрд▓рд╛рдпрд╛ рдЬрдм рд░рд╛рдЬреНрдпрдкрд╛рд▓ рд╕реАрдврд╝рд┐рдпреЛрдВ рд╕реЗ рдКрдкрд░ рдЬрд╛ рд░рд╣реЗ рдереЗ рдФрд░ рдорд┐рд▓реНрд╡реМрдХреА рдмреНрд░реВрд╡рд░реНрд╕ рдФрд░ рд╢рд┐рдХрд╛рдЧреЛ рд╢рд╛рд╡рдХреЛрдВ рдХреЗ рдмреАрдЪ рдЦреЗрд▓ рдХреЗ рджреМрд░рд╛рди рдЙрдиреНрд╣реЗрдВ \"рдкрд╛рдЦрдВрдбреА\" рдХрд╣рд╛редтАЬ(рд╡рд╣) рдореБрдЭ рдкрд░ рдЪрд┐рд▓реНрд▓рд╛ рд░рд╣рд╛ рдерд╛редрдкрд╣рд▓реЗ рдЙрдиреНрд╣реЛрдВрдиреЗ рдореБрдЭрд╕реЗ рдХрд╣рд╛, тАШрдЖрдкрдХреЗ рдкрд╛рд╕ рдПрдХ рдФрд░ рдмреАрдпрд░ рдХреНрдпреЛрдВ рдирд╣реАрдВ рд╣реИ?\"рдлрд┐рд░ рдЙрд╕рдиреЗ рдореБрдЭреЗ рдПрдХ рдХрдард┐рди рдЖрджрдореА рдХрд╣рдирд╛ рд╢реБрд░реВ рдХрд░ рджрд┐рдпрд╛ред\"рдХреНрд░рд┐рд╕реНрдЯреА рдХреЗ рдХрд╛рд░реНрдпрд╛рд▓рдп рдХреЗ рдПрдХ рдкреНрд░рддрд┐рдирд┐рдзрд┐ рдиреЗ рд╕реЛрдорд╡рд╛рд░ рдХреЛ рдЯрд┐рдкреНрдкрдгреА рдХреЗ рдЕрдиреБрд░реЛрдз рдХрд╛ рддреБрд░рдВрдд рдЬрд╡рд╛рдм рдирд╣реАрдВ рджрд┐рдпрд╛редрдХрдИ рд╕реЛрд╢рд▓ рдореАрдбрд┐рдпрд╛ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛рдУрдВ рдиреЗ рдХреНрд░рд┐рд╕реНрдЯреА рдХреЗ рдХрд╛рд░реНрдпреЛрдВ рдкрд░ рдЕрдкрдирд╛ рдЧреБрд╕реНрд╕рд╛ рд╡реНрдпрдХреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЯреНрд╡рд┐рдЯрд░ рдкрд░ рд▓рд┐рдпрд╛редрдХреЙрдореЗрдбрд┐рдпрди рдирд┐рдХ рдЬреИрдХ рдкрдкреНрдкрд╕ рдиреЗ рд░рд╡рд┐рд╡рд╛рд░ рдХреЛ рдЯреНрд╡реАрдЯ рдХрд┐рдпрд╛, \"рдХреНрд░рд┐рд╕ рдХреНрд░рд┐рд╕реНрдЯреА рдиреЗ рд╕рд┐рд░реНрдл рд╕рд╛рдмрд┐рдд рдХрд┐рдпрд╛ рдХрд┐ рдЖрдкрдХреА рдкреИрдВрдЯ рдХреЛ рдЖрдкрдХреА рдЫрд╛рддреА рддрдХ рдЦреАрдВрдЪреА рдЧрдИ рдкреИрдВрдЯ рдХреЗ рд╕рд╛рде рдХрдард┐рди рджрд┐рдЦрдирд╛ рдЕрд╕рдВрднрд╡ рд╣реИред\"рдЬрд╝реИрдЪ рдереБрд░рдорди рдиреЗ рд╕реЛрдорд╡рд╛рд░ рдХреЛ рдЯреНрд╡реАрдЯ рдХрд┐рдпрд╛, \"рдпрд╛рд░ рдХрд╕реНрдЯрд╛ рдиреЗ рдЙрди рдирд╛рдЪреЛрдВ рдХреЛ @chrischristie рд╣рд╛рдереЛрдВ рд╕реЗ рдмрд╛рд╣рд░ рдирд┐рдХрд╛рд▓ рджрд┐рдпрд╛ рдФрд░ рдЙрдиреНрд╣реЗрдВ рдХрд╣рд╛ рдХрд┐ рд╡реЗ 'рдмрдВрдж' рд╕рд╛рд░реНрд╡рдЬрдирд┐рдХ рд╕рдореБрджреНрд░ рддрдЯ рдкрд░ рд╡рд╛рдкрд╕ рдЬрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд╣реЗрдВ, рдЬрд╣рд╛рдВ рдпрд╣ рд╕реБрд░рдХреНрд╖рд┐рдд рд╣реИред\"рдХреНрд░рд┐рд╕реНрдЯреА рдиреЗ рдЗрд╕ рдорд╣реАрдиреЗ рдХреА рд╢реБрд░реБрдЖрдд рдореЗрдВ рдПрдХ рдиреНрдпреВ рдЬрд░реНрд╕реА рд╕реНрдЯреЗрдЯ рдмреАрдЪ рдкрд░ рдЖрд░рд╛рдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕реНрд▓реИрдо рд╣реЛрдиреЗ рдХреЗ рдмрд╛рдж рдПрдХ рд╕рд░рдХрд╛рд░реА рд╢рдЯрдбрд╛рдЙрди рдХреЗ рдмреАрдЪ рд╕реБрд░реНрдЦрд┐рдпрд╛рдВ рдмрдЯреЛрд░реАрдВ, рдЬрд┐рд╕рдиреЗ рд╕рдореБрджреНрд░ рддрдЯ рдХреЛ рдмрд╛рдХреА рд╕рднреА рдХреЗ рд▓рд┐рдП рд╕реАрдорд╛ рд╕реЗ рджреВрд░ рдХрд░ рджрд┐рдпрд╛редрдПрдХ рд╕рдореБрджреНрд░ рддрдЯ рдХреА рдХреБрд░реНрд╕реА рдореЗрдВ рдХреНрд░рд┐рд╕реНрдЯреА рдХреА рдкрд░рд┐рд╡рд░реНрддрд┐рдд рддрд╕реНрд╡реАрд░реЗрдВ рдЗрдВрдЯрд░рдиреЗрдЯ рдкрд░ рдлреИрд▓реА рд╣реБрдИ рд╣реИрдВ, рдЬрд┐рд╕рдореЗрдВ рдЙрдиреНрд╣реЗрдВ рд╡реНрд╣рд╛рдЗрдЯ рд╣рд╛рдЙрд╕ рдХреА рдмреИрдардХ, рдлрд┐рд▓реНрдо рдФрд░ рдЯреЗрд▓реАрд╡рд┐рдЬрди рджреГрд╢реНрдпреЛрдВ рдФрд░ рдЕрдиреНрдп рдЕрдкреНрд░рддреНрдпрд╛рд╢рд┐рдд рд╕реЗрдЯрд┐рдВрдЧреНрд╕ рдХрд╛ рдЪрд┐рддреНрд░рдг рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИредрдХреНрд░рд┐рд╕реНрдЯреА рд╕рдмрд╕реЗ рдирд╛рдкрд╕рдВрдж рдЕрдореЗрд░рд┐рдХреА рдореЗрдВ рд╕реЗ рдПрдХ рд╣реИрдЧрд╡рд░реНрдирд░, рдЬреВрди рдореЗрдВ рдПрдХ рдХреНрд╡рд┐рдирд┐рдкрд┐рдпрд╛рдХ рдпреВрдирд┐рд╡рд░реНрд╕рд┐рдЯреА рдкреЛрд▓ рдХреЗ рд╕рд╛рде рдпрд╣ рдкрд╛рддреЗ рд╣реБрдП рдХрд┐ 10 рдиреНрдпреВ рдЬрд░реНрд╕реА рдорддрджрд╛рддрд╛рдУрдВ рдореЗрдВ рд╕реЗ рдЖрда рдиреМрдХрд░реА рд╕реЗ рдЕрд╕реНрд╡реАрдХрд╛рд░ рдХрд░ рд░рд╣реЗ рдереЗ, рдЬреЛ рдпрд╣ рдХрд╣рд╛ рдЧрдпрд╛ рдерд╛ рдХрд┐ рдпрд╣ рдХрд┐рд╕реА рднреА рдЧрд╡рд░реНрдирд░ рдФрд░ рд╕рдмрд╕реЗ рдХрдо рдиреМрдХрд░реА рдХреА рдордВрдЬреВрд░реА рдХреА рд░реЗрдЯрд┐рдВрдЧ рдереА рдЬреЛ рдЗрд╕реЗ 20 рд╡рд░реНрд╖реЛрдВ рдореЗрдВ рдХрд┐рд╕реА рднреА рдЧрд╡рд░реНрдирд░ рдХреЗ рд▓рд┐рдП рдорд┐рд▓реА рдереАред\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Real News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  \ttext 10420\tрдпрджрд┐ рдЕрдореЗрд░рд┐рдХреА рд░рд╛рдЬреНрдп рд╡рд┐рднрд╛рдЧ 16 рдорд╛рд░реНрдЪ рд╕реЗ рд╢реБрд░реВ рд╣реЛрдиреЗ рдХреЗ рд▓рд┐рдП 120-рджрд┐рди рдХреЗ рдард╣рд░рд╛рд╡ рдХреА рддреИрдпрд╛рд░реА рдХрд░ рд░рд╣рд╛ рдерд╛, рддреЛ рдпрд╣ рдХреИрд╕реЗ рд╣реИ рдХрд┐ рдпрд╣ рдмрдбрд╝реА рд╕рдВрдЦреНрдпрд╛ рдореЗрдВ рд╢рд░рдгрд╛рд░реНрдереА рд╡рд┐рдорд╛рдиреЛрдВ рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рдереЗ?рдХреНрдпрд╛ рдХреЛрдИ рдкреНрд░рднрд╛рд░реА (рдХреИрд░рд┐рдпрд░ рдХреЗ рд▓реЛрдЧреЛрдВ рдХреЗ рдЕрд▓рд╛рд╡рд╛) рдЬрдирд╕рдВрдЦреНрдпрд╛, рд╢рд░рдгрд╛рд░реНрдерд┐рдпреЛрдВ рдФрд░ рдкреНрд░рд╡рд╛рд╕ рдмреНрдпреВрд░реЛ рдореЗрдВ рд╣реИ?рдХреНрдпрд╛ рд╡реЗ рдЕрднреА рднреА рд╕рднреА рд╢реЙрдЯреНрд╕ рдХрд╣ рд░рд╣реЗ рд╣реИрдВ?рдпрд╛, рдХреНрдпрд╛ рдпрд╣ рд╕рдВрднрд╡ рд╣реИ рдХрд┐ рд╡реНрд╣рд╛рдЗрдЯ рд╣рд╛рдЙрд╕ рдиреЗ рдХрд╛рд░реНрдпрдХрд╛рд░реА рдЖрджреЗрд╢ рдХреЗ рдЗрд╕ рд╣рд┐рд╕реНрд╕реЗ рдкрд░ рд▓рдбрд╝рдиреЗ рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рдирд╣реАрдВ рдХрд┐рдпрд╛ (рдпрд╣ рдорд╛рдирддреЗ рд╣реБрдП рдХрд┐ рд╣рдо рдЯреА рдиреЛрдЯрд┐рд╕ рдирд╣реАрдВ рдХрд░реЗрдВрдЧреЗ)? 342 рдирдП рдЖрдЧрдорди рдХреЗ рдмреАрдЪ рд╢реАрд░реНрд╖ рдкрд╛рдВрдЪ рд░рд╛рд╖реНрдЯреНрд░реАрдпрддрд╛рдПрдВ рдЗрд╕ рдкреНрд░рдХрд╛рд░ рд╣реИрдВ: рд╕реАрд░рд┐рдпрд╛ (55 рдФрд░ 51 рдЙрдирдореЗрдВ рд╕реЗ рдереЗредрдореБрд╕реНрд▓рд┐рдо) рд╕реЛрдорд╛рд▓рд┐рдпрд╛ (50 рдФрд░ рд╕рднреА рдореБрд╕реНрд▓рд┐рдо рд╣реИрдВ) рдмрд░реНрдорд╛ (44 рдФрд░ рдЙрди 17 рдХреА рдЖрд╢реНрдЪрд░реНрдпрдЬрдирдХ рд░реВрдк рд╕реЗ рдЙрдЪреНрдЪ рд╕рдВрдЦреНрдпрд╛ рдореБрд╕реНрд▓рд┐рдо рд╣реИрдВ) рдЗрд░рд╛рдХ (41 рдФрд░ 32 рдореБрд╕реНрд▓рд┐рдо рд╣реИрдВ)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"./fake-news-multilingual\n",
    "\"  # Change this to your fine-tuned model path if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to predict the label\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    label = \"Fake News\" if predicted_class == 1 else \"Real News\"\n",
    "    return label\n",
    "\n",
    "# Get user input and predict\n",
    "while True:\n",
    "    text = input(\"Enter text to classify (or type 'exit' to quit): \")\n",
    "    if text.lower() == \"exit\":\n",
    "        break\n",
    "    prediction = predict(text)\n",
    "    print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a78c94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104e9ff-d679-4fbf-8bc3-623b361c14b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-08T01:56:15.077728Z",
     "iopub.status.busy": "2025-03-08T01:56:15.077301Z",
     "iopub.status.idle": "2025-03-08T01:56:15.088113Z",
     "shell.execute_reply": "2025-03-08T01:56:15.086921Z",
     "shell.execute_reply.started": "2025-03-08T01:56:15.077695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fake-news-detection/final_data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:09:21.187166Z",
     "iopub.status.busy": "2025-03-08T02:09:21.186778Z",
     "iopub.status.idle": "2025-03-08T02:09:25.672068Z",
     "shell.execute_reply": "2025-03-08T02:09:25.670727Z",
     "shell.execute_reply.started": "2025-03-08T02:09:21.187122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.0a2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.29.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:15:13.408964Z",
     "iopub.status.busy": "2025-03-08T02:15:13.408434Z",
     "iopub.status.idle": "2025-03-08T02:15:18.517249Z",
     "shell.execute_reply": "2025-03-08T02:15:18.515479Z",
     "shell.execute_reply.started": "2025-03-08T02:15:13.408928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.65.4\n",
      "    Uninstalling openai-1.65.4:\n",
      "      Successfully uninstalled openai-1.65.4\n",
      "Successfully installed openai-0.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:20:38.939957Z",
     "iopub.status.busy": "2025-03-08T02:20:38.939442Z",
     "iopub.status.idle": "2025-03-08T02:21:11.238158Z",
     "shell.execute_reply": "2025-03-08T02:21:11.236879Z",
     "shell.execute_reply.started": "2025-03-08T02:20:38.939917Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langdetect import detect\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:21:40.066456Z",
     "iopub.status.busy": "2025-03-08T02:21:40.065654Z",
     "iopub.status.idle": "2025-03-08T02:22:00.115963Z",
     "shell.execute_reply": "2025-03-08T02:22:00.114438Z",
     "shell.execute_reply.started": "2025-03-08T02:21:40.066415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63380d44d2d64b93bdace380f4f0b901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/734 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b503ba0d754347ab75bdbd55328d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8e9c83bb444b9faf96882a7185e7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a9eb2edadb4538ad712ffff077eba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd00314826604e97a2d367d9156c251d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load a multilingual LLM for text classification\n",
    "classifier = pipeline(\"text-classification\", model=\"joeddav/xlm-roberta-large-xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:26:47.454379Z",
     "iopub.status.busy": "2025-03-08T02:26:47.453945Z",
     "iopub.status.idle": "2025-03-08T02:26:47.460757Z",
     "shell.execute_reply": "2025-03-08T02:26:47.459524Z",
     "shell.execute_reply.started": "2025-03-08T02:26:47.454346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Define credible and non-credible sources for multiple languages\n",
    "credible_sources = {\n",
    "    \"en\": [\"bbc.com\", \"reuters.com\", \"nytimes.com\"],  # English\n",
    "    \"es\": [\"elpais.com\", \"bbc.com/mundo\"],           # Spanish\n",
    "    \"fr\": [\"lemonde.fr\", \"bbc.com/afrique\"],         # French\n",
    "    \"de\": [\"spiegel.de\", \"zeit.de\"],                 # German\n",
    "}\n",
    "\n",
    "non_credible_sources = {\n",
    "    \"en\": [\"fakenews.com\", \"unreliable.com\"],\n",
    "    \"es\": [\"noticiasfalsas.es\"],\n",
    "    \"fr\": [\"fauxnews.fr\"],\n",
    "    \"de\": [\"luegenpresse.de\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:22:47.756450Z",
     "iopub.status.busy": "2025-03-08T02:22:47.755153Z",
     "iopub.status.idle": "2025-03-08T02:22:47.764561Z",
     "shell.execute_reply": "2025-03-08T02:22:47.763169Z",
     "shell.execute_reply.started": "2025-03-08T02:22:47.756391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Function to detect the language of the text\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"en\"  # Default to English if language detection fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:23:17.419485Z",
     "iopub.status.busy": "2025-03-08T02:23:17.418984Z",
     "iopub.status.idle": "2025-03-08T02:23:17.427393Z",
     "shell.execute_reply": "2025-03-08T02:23:17.426014Z",
     "shell.execute_reply.started": "2025-03-08T02:23:17.419441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Function to calculate credibility score\n",
    "def calculate_credibility_score(text, sources, language):\n",
    "    credible_count = 0\n",
    "    total_count = len(sources)\n",
    "    \n",
    "    for source in sources:\n",
    "        if source in text.lower():\n",
    "            if source in credible_sources.get(language, []):\n",
    "                credible_count += 1\n",
    "            elif source in non_credible_sources.get(language, []):\n",
    "                credible_count -= 1\n",
    "    \n",
    "    credibility_score = credible_count / total_count if total_count > 0 else 0\n",
    "    return credibility_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:23:33.163153Z",
     "iopub.status.busy": "2025-03-08T02:23:33.162777Z",
     "iopub.status.idle": "2025-03-08T02:23:33.170166Z",
     "shell.execute_reply": "2025-03-08T02:23:33.168758Z",
     "shell.execute_reply.started": "2025-03-08T02:23:33.163122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Function to detect if text is real or fake\n",
    "def detect_real_or_fake(text, sources):\n",
    "    # Detect language\n",
    "    language = detect_language(text)\n",
    "    \n",
    "    # Analyze text using multilingual LLM\n",
    "    llm_result = classifier(text)[0]\n",
    "    llm_label = llm_result['label']\n",
    "    llm_confidence = llm_result['score']\n",
    "    \n",
    "    # Calculate credibility score\n",
    "    credibility_score = calculate_credibility_score(text, sources, language)\n",
    "    \n",
    "    # Combine LLM result and credibility score\n",
    "    if llm_label == \"LABEL_1\" and credibility_score > 0.5:  # LABEL_1 is typically \"entailment\" or \"real\"\n",
    "        return \"Real\", credibility_score\n",
    "    else:\n",
    "        return \"Fake\", credibility_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:26:50.916609Z",
     "iopub.status.busy": "2025-03-08T02:26:50.916230Z",
     "iopub.status.idle": "2025-03-08T02:26:51.226845Z",
     "shell.execute_reply": "2025-03-08T02:26:51.225579Z",
     "shell.execute_reply.started": "2025-03-08T02:26:50.916578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Fake, Credibility Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Example usage\n",
    "text = \"Según bbc.com/mundo, la nueva política mejorará la atención médica.\"  # Spanish text\n",
    "sources = [\"bbc.com/mundo\", \"noticiasfalsas.es\"]\n",
    "\n",
    "result, score = detect_real_or_fake(text, sources)\n",
    "print(f\"Result: {result}, Credibility Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:29:03.405957Z",
     "iopub.status.busy": "2025-03-08T02:29:03.405484Z",
     "iopub.status.idle": "2025-03-08T02:29:03.411067Z",
     "shell.execute_reply": "2025-03-08T02:29:03.409834Z",
     "shell.execute_reply.started": "2025-03-08T02:29:03.405926Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from langdetect import detect\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:29:39.096843Z",
     "iopub.status.busy": "2025-03-08T02:29:39.096398Z",
     "iopub.status.idle": "2025-03-08T02:29:44.301174Z",
     "shell.execute_reply": "2025-03-08T02:29:44.299746Z",
     "shell.execute_reply.started": "2025-03-08T02:29:39.096806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load a multilingual LLM for text classification\n",
    "classifier = pipeline(\"text-classification\", model=\"joeddav/xlm-roberta-large-xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:54:42.105910Z",
     "iopub.status.busy": "2025-03-08T02:54:42.105218Z",
     "iopub.status.idle": "2025-03-08T02:54:42.114302Z",
     "shell.execute_reply": "2025-03-08T02:54:42.112777Z",
     "shell.execute_reply.started": "2025-03-08T02:54:42.105868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Function to extract key phrases (for searching)\n",
    "def extract_key_phrases(text):\n",
    "    # Use a simple approach (e.g., split into sentences or keywords)\n",
    "    # For better results, use a library like `spacy` or `rake-nltk`\n",
    "    return text.split(\". \")[0]  # Extract the first sentence as a key phrase\n",
    "\n",
    "# Step 4: Function to search for source links using Google Custom Search API\n",
    "def search_source_links(query, language=\"en\"):\n",
    "    api_key = \"AIzaSyAGWiKG9FtySaQaWQ8CkrWP39x17Vg2s0M\"  # Replace with your Google API key\n",
    "    search_engine_id = \"c7aec10c934ce4e1e\"  # Replace with your Search Engine ID\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={search_engine_id}&lr=lang_{language}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            results = response.json()\n",
    "            links = [item[\"link\"] for item in results.get(\"items\", [])]\n",
    "            return links\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T03:01:05.693745Z",
     "iopub.status.busy": "2025-03-08T03:01:05.693329Z",
     "iopub.status.idle": "2025-03-08T03:01:05.699989Z",
     "shell.execute_reply": "2025-03-08T03:01:05.698533Z",
     "shell.execute_reply.started": "2025-03-08T03:01:05.693711Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_text_with_source_links(text):\n",
    "    # Detect language\n",
    "    language = detect_language(text)\n",
    "    \n",
    "    # Classify text using multilingual LLM\n",
    "    llm_result = classifier(text)[0]\n",
    "    llm_label = llm_result['label']\n",
    "    llm_confidence = llm_result['score']\n",
    "    \n",
    "    # Extract key phrases for searching\n",
    "    key_phrase = extract_key_phrases(text)\n",
    "    \n",
    "    # Search for source links\n",
    "    source_links = search_source_links(key_phrase, language)\n",
    "    \n",
    "    # Determine if the text is real or fake\n",
    "    if llm_label == \"LABEL_0\" and source_links:  # LABEL_1 is typically \"entailment\" or \"real\"\n",
    "        result = \"Real\"\n",
    "    else:\n",
    "        result = \"Fake\"\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"confidence\": llm_confidence,\n",
    "        \"source_links\": source_links,\n",
    "        \"language\": language,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:59:12.556338Z",
     "iopub.status.busy": "2025-03-08T02:59:12.555783Z",
     "iopub.status.idle": "2025-03-08T02:59:12.561432Z",
     "shell.execute_reply": "2025-03-08T02:59:12.560205Z",
     "shell.execute_reply.started": "2025-03-08T02:59:12.556294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Save results to a file for faster reruns\n",
    "def save_results(results, filename=\"/kaggle/working/results.csv\"):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T02:56:09.389618Z",
     "iopub.status.busy": "2025-03-08T02:56:09.389121Z",
     "iopub.status.idle": "2025-03-08T02:56:09.395352Z",
     "shell.execute_reply": "2025-03-08T02:56:09.393845Z",
     "shell.execute_reply.started": "2025-03-08T02:56:09.389555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Load results from a file (if available)\n",
    "def load_results(filename=\"/kaggle/working/results.csv\"):\n",
    "    try:\n",
    "        return pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T03:00:30.538925Z",
     "iopub.status.busy": "2025-03-08T03:00:30.538487Z",
     "iopub.status.idle": "2025-03-08T03:00:30.543550Z",
     "shell.execute_reply": "2025-03-08T03:00:30.542466Z",
     "shell.execute_reply.started": "2025-03-08T03:00:30.538890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 8: Example usage\n",
    "text = \"Según bbc.com/mundo, la nueva política mejorará la atención médica.\"  # Spanish text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T03:01:09.009933Z",
     "iopub.status.busy": "2025-03-08T03:01:09.009500Z",
     "iopub.status.idle": "2025-03-08T03:01:09.661001Z",
     "shell.execute_reply": "2025-03-08T03:01:09.659765Z",
     "shell.execute_reply.started": "2025-03-08T03:01:09.009898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New result:\n",
      "{'text': 'Según bbc.com/mundo, la nueva política mejorará la atención médica.', 'confidence': 0.9891669750213623, 'source_links': ['https://www.bbc.com/mundo/vert-fut-59568598', 'https://www.bbc.com/mundo/noticias-46638119', 'https://www.bbc.com/mundo/noticias-america-latina-48275780', 'https://www.bbc.com/mundo/articles/cxrz3prg06wo', 'https://www.bbc.com/mundo/noticias-51710459', 'https://www.bbc.com/mundo/noticias-internacional-53440439', 'https://www.bbc.com/mundo/noticias-internacional-65911893', 'https://www.bbc.com/mundo/noticias-47543716', 'https://www.bbc.com/mundo/noticias-internacional-45582530', 'https://www.bbc.com/mundo/articles/c51vekykvgqo'], 'language': 'es'}\n"
     ]
    }
   ],
   "source": [
    "# Classify the text and save results\n",
    "result = classify_text_with_source_links(text)\n",
    "save_results([result])\n",
    "print(\"New result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6754082,
     "sourceId": 10871197,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
